{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "<p><font size=\"6\"><b> CASE - air quality data of European monitoring stations (AirBase)</b></font></p>\n",
    "\n",
    "> *© 2025, Joris Van den Bossche and Stijn Van Hoey  (<mailto:jorisvandenbossche@gmail.com>, <mailto:stijnvanhoey@gmail.com>). Licensed under [CC BY 4.0 Creative Commons](http://creativecommons.org/licenses/by/4.0/)*\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "We processed some raw data files of the AirBase air quality data. The data contains hourly concentrations of nitrogen dioxide (NO2) for 4 different measurement stations:\n",
    "\n",
    "- FR04037 (PARIS 13eme): urban background site at Square de Choisy\n",
    "- FR04012 (Paris, Place Victor Basch): urban traffic site at Rue d'Alesia\n",
    "- BETR802: urban traffic site in Antwerp, Belgium\n",
    "- BETN029: rural background site in Houtem, Belgium\n",
    "\n",
    "See http://www.eea.europa.eu/themes/air/interactive/no2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Importing and quick exploration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "We processed the individual data files in the previous notebook ([case4_air_quality_processing.ipynb](case4_air_quality_processing.ipynb)), and saved it to a csv file `airbase_data_processed.csv`. Let's import the file here (if you didn't finish the previous notebook, a set of the pre-processed dataset if also available in `data/airbase_data.csv`):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "alldata = pd.read_csv('data/airbase_data.csv', index_col=0, parse_dates=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "We only use the data from 1999 onwards:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "data = alldata['1999':].copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "Some first exploration with the *typical* functions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "data.head() # tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "data.describe(percentiles=[0.1, 0.5, 0.9])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "data.plot(figsize=(12,6))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "<div class=\"alert alert-warning\">\n",
    "\n",
    "**ATTENTION!**:\n",
    "\n",
    "When just using `.plot()` without further notice (selection, aggregation,...)\n",
    "\n",
    "* Risk of running into troubles by overloading your computer processing (certainly with looooong time series).\n",
    "* Not always the most informative/interpretable visualisation.\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "**Plot only a subset**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "Why not just using the `head`/`tail` possibilities?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "data.tail(500).plot(figsize=(12,6))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "**Summary figures**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "Use summary statistics..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "data.plot(kind='box', ylim=[0,250])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "Also with seaborn plots function, just start with some subsets as first impression...\n",
    "\n",
    "As we already have seen previously, the plotting library [seaborn](http://seaborn.pydata.org/generated/seaborn.heatmap.html) provides some high-level plotting functions on top of matplotlib (check the [docs](http://seaborn.pydata.org/examples/index.html)!). One of those functions is `pairplot`, which we can use here to quickly visualize the concentrations at the different stations and their relation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "sns.pairplot(data.tail(5000).dropna())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Is this a tidy dataset ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "In principle this is not a tidy dataset. The variable that was measured is the NO2 concentration, and is divided in 4 columns. Of course those measurements were made at different stations, so one could interpret it as separate variables. But in any case, such format does not always work well with libraries like `seaborn` which expects a pure tidy format.\n",
    "\n",
    "\n",
    "Reason to not use a tidy dataset here: \n",
    "\n",
    "* smaller memory use\n",
    "* timeseries functionality like resample works better\n",
    "* pandas plotting already does what we want when having different columns for *some* types of plots (eg line plots of the timeseries)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "<div class=\"alert alert-success\">\n",
    "\n",
    "__EXERCISE__\n",
    "\n",
    "- Create a tidy version of this dataset <code>data_tidy</code>, ensuring the result has new columns 'station' and 'no2'.\n",
    "- Check how many missing values are contained in the 'no2' column.\n",
    "- Drop the rows with missing values in that column.\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "nbtutor-solution"
    ]
   },
   "outputs": [],
   "source": [
    "data_tidy = data.reset_index().melt(id_vars=[\"datetime\"], var_name='station', value_name='no2')\n",
    "data_tidy.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "nbtutor-solution"
    ]
   },
   "outputs": [],
   "source": [
    "data_tidy['no2'].isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "nbtutor-solution"
    ]
   },
   "outputs": [],
   "source": [
    "data_tidy = data_tidy.dropna()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "In the following exercises we will mostly do our analysis on `data`and often use pandas plotting, but once we produced some kind of summary dataframe as the result of an analysis, then it becomes more interesting to convert that result to a tidy format to be able to use the more advanced plotting functionality of seaborn."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Exercises"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "<div class=\"alert alert-warning\">\n",
    "\n",
    "__REMINDER__\n",
    "\n",
    "Take a look at the [Timeseries notebook](pandas_04_time_series_data.ipynb) when you require more info about:\n",
    "\n",
    "- `resample`\n",
    "- string indexing of DateTimeIndex\n",
    "\n",
    "Take a look at the [matplotlib](visualization_01_matplotlib.ipynb) and [seaborn](visualization_02_seaborn.ipynb) notebooks when you require more info about the plot requirements.\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "<div class=\"alert alert-success\">\n",
    "\n",
    "__EXERCISE__\n",
    "\n",
    "Plot the monthly mean and median concentration of the 'FR04037' station for the years 2009 - 2013 in a single figure/ax.\n",
    "\n",
    "<details><summary>Hints</summary>\n",
    "\n",
    "- The symbol for monthly resampling is either `ME` or `MS`.\n",
    "\n",
    "</details>\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "nbtutor-solution"
    ]
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "data.loc['2009':, 'FR04037'].resample('ME').mean().plot(ax=ax, label='mean')\n",
    "data.loc['2009':, 'FR04037'].resample('ME').median().plot(ax=ax, label='median')\n",
    "ax.legend(ncol=2)\n",
    "ax.set_title(\"FR04037\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "nbtutor-solution"
    ]
   },
   "outputs": [],
   "source": [
    "data.loc['2009':, 'FR04037'].resample('ME').agg(['mean', 'median']).plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "<div class=\"alert alert-success\">\n",
    "\n",
    "<b>EXERCISE</b>\n",
    "\n",
    " <ul>\n",
    "  <li>Make a violin plot for January 2011 until August 2011 (check out the documentation to improve the plotting settings)</li>\n",
    "  <li>Change the y-label to 'NO$_2$ concentration (µg/m³)'</li>\n",
    "</ul><br>\n",
    "\n",
    "_NOTE:_ In this case, we can use seaborn both with the data not in a long format but when having different columns for which you want to make violin plots, as with the tidy data.\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "nbtutor-solution"
    ]
   },
   "outputs": [],
   "source": [
    "# with wide dataframe\n",
    "fig, ax = plt.subplots()\n",
    "sns.violinplot(data=data['2011-01': '2011-08'], color=\"C0\", ax=ax)\n",
    "ax.set_ylabel(\"NO$_2$ concentration (µg/m³)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "nbtutor-solution"
    ]
   },
   "outputs": [],
   "source": [
    "# with tidy dataframe\n",
    "data_tidy_subset = data_tidy[(data_tidy['datetime'] >= \"2011-01\") & (data_tidy['datetime'] < \"2011-09\")]\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "sns.violinplot(data=data_tidy_subset, x=\"station\", y=\"no2\", color=\"C0\", ax=ax)\n",
    "ax.set_ylabel(\"NO$_2$ concentration (µg/m³)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "nbtutor-solution"
    ]
   },
   "outputs": [],
   "source": [
    "# with figure-level function\n",
    "sns.catplot(data=data_tidy_subset, x=\"station\", y=\"no2\", kind=\"violin\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "<div class=\"alert alert-success\">\n",
    "\n",
    "<b>EXERCISE</b>\n",
    "\n",
    " <ul>\n",
    "  <li>Make a bar plot with pandas of the mean of each of the stations in the year 2012 (check the documentation of Pandas plot to adapt the rotation of the labels) and make sure all bars have the same color.</li>\n",
    "  <li>Using the matplotlib objects, change the y-label to 'NO$_2$ concentration (µg/m³)</li>\n",
    "  <li>Add a 'darkorange' horizontal line on the ax for the y-value 40 µg/m³ (command for horizontal line from matplotlib: <code>axhline</code>).</li>\n",
    "  <li><a href=\"visualization_01_matplotlib.ipynb\">Place the text</a> 'Yearly limit is 40 µg/m³' just above the 'darkorange' line.</li>\n",
    "</ul>\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "nbtutor-solution"
    ]
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "data['2012':].mean().plot(kind='bar', ax=ax, rot=0, color='C0')\n",
    "ax.set_ylabel(\"NO$_2$ concentration (µg/m³)\")\n",
    "ax.axhline(y=40., color='darkorange')\n",
    "ax.text(0.3, 0.48, 'Yearly limit is 40 µg/m³',\n",
    "        horizontalalignment='left', fontsize=13, \n",
    "        transform=ax.transAxes, color='darkorange');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "<div class=\"alert alert-success\">\n",
    "\n",
    "__EXERCISE__\n",
    "\n",
    "Did the air quality improve over time?\n",
    "\n",
    "- For the data from 1999 till the end, plot the yearly averages\n",
    "- For the same period, add the overall mean (all stations together) as an additional line to the graph, use a thicker black line (<code>linewidth=4</code> and <code>linestyle='--'</code>)\n",
    "- [OPTIONAL] Add a legend above the ax for all lines\n",
    "  \n",
    "\n",
    "</ul>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "nbtutor-solution"
    ]
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "\n",
    "data['1999':].resample('YE').mean().plot(ax=ax)\n",
    "data['1999':].mean(axis=1).resample('YE').mean().plot(color='k', \n",
    "                                            linestyle='--', \n",
    "                                            linewidth=4, \n",
    "                                            ax=ax, \n",
    "                                            label='Overall mean')\n",
    "ax.legend(loc='center', ncol=3, \n",
    "          bbox_to_anchor=(0.5, 1.06))\n",
    "ax.set_ylabel(\"NO$_2$ concentration (µg/m³)\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "<div class=\"alert alert-info\">\n",
    "\n",
    "**REMEMBER**:\n",
    "\n",
    "`resample` is a special version of a`groupby` operation. For example, taking annual means with `data.resample('A').mean()` is equivalent to `data.groupby(data.index.year).mean()` (but the result of `resample` still has a DatetimeIndex).\n",
    "\n",
    "Checking the index of the resulting DataFrame when using **groupby** instead of resample: You'll notice that the Index lost the DateTime capabilities:\n",
    "\n",
    "```python\n",
    ">>> data.groupby(data.index.year).mean().index\n",
    "```\n",
    "<br>\n",
    "\n",
    "Results in:\n",
    "\n",
    "```\n",
    "Int64Index([1990, 1991, 1992, 1993, 1994, 1995, 1996, 1997, 1998, 1999, 2000,\n",
    "            2001, 2002, 2003, 2004, 2005, 2006, 2007, 2008, 2009, 2010, 2011,\n",
    "            2012],\n",
    "           dtype='int64')$\n",
    "```\n",
    "<br>\n",
    "\n",
    "When using **resample**, we keep the DateTime capabilities:\n",
    "\n",
    "```python\n",
    ">>> data.resample('A').mean().index\n",
    "```\n",
    "<br>\n",
    "\n",
    "Results in:\n",
    "\n",
    "```\n",
    "DatetimeIndex(['1999-12-31', '2000-12-31', '2001-12-31', '2002-12-31',\n",
    "               '2003-12-31', '2004-12-31', '2005-12-31', '2006-12-31',\n",
    "               '2007-12-31', '2008-12-31', '2009-12-31', '2010-12-31',\n",
    "               '2011-12-31', '2012-12-31'],\n",
    "              dtype='datetime64[ns]', freq='A-DEC')\n",
    "```\n",
    "<br>\n",
    "\n",
    "But, `groupby` is more flexible and can also do resamples that do not result in a new continuous time series, e.g. by grouping by the hour of the day to get the diurnal cycle.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "<div class=\"alert alert-success\">\n",
    "\n",
    "__EXERCISE__\n",
    "\n",
    "How does the <i>typical yearly profile</i> (typical averages for the different months over the years) look like for the different stations? (add a 'month' column as a first step)\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "nbtutor-solution"
    ]
   },
   "outputs": [],
   "source": [
    "# add a column to the dataframe that indicates the month (integer value of 1 to 12):\n",
    "data['month'] = data.index.month\n",
    "\n",
    "# now, we can calculate the mean of each month over the different years:\n",
    "data.groupby('month').mean()\n",
    "\n",
    "# plot the typical monthly profile of the different stations:\n",
    "data.groupby('month').mean().plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "Remove the temporary 'month' column generated in the solution of the previous exercise:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "data = data.drop(\"month\", axis=1, errors=\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "Note: Technically, we could reshape the result of the groupby operation to a tidy format (we no longer have a real time series), but since we already have the things we want to plot as lines in different columns, doing `.plot` already does what we want."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "<div class=\"alert alert-success\">\n",
    "\n",
    "__EXERCISE__\n",
    "\n",
    "Plot the weekly 95% percentiles of the concentration in 'BETR801' and 'BETN029' for 2011\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "nbtutor-solution"
    ]
   },
   "outputs": [],
   "source": [
    "# Resample wise\n",
    "df2011 = data.loc['2011']\n",
    "df2011[['BETN029', 'BETR801']].resample('W').quantile(0.95).plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "nbtutor-solution"
    ]
   },
   "outputs": [],
   "source": [
    "# Groupby wise\n",
    "# Note the different x-axis labels\n",
    "df2011.groupby(df2011.index.isocalendar().week)[['BETN029', 'BETR801']].quantile(0.95).plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "<div class=\"alert alert-success\">\n",
    "\n",
    "__EXERCISE__\n",
    "\n",
    "Plot the typical diurnal profile (typical hourly averages) for the different stations taking into account the whole time period.\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "nbtutor-solution"
    ]
   },
   "outputs": [],
   "source": [
    "data.groupby(data.index.hour).mean().plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "<div class=\"alert alert-success\">\n",
    "\n",
    "__EXERCISE__\n",
    "\n",
    "What is the difference in the typical diurnal profile between week and weekend days? (and visualise it)\n",
    "\n",
    "Start with only visualizing the different in diurnal profile for the 'BETR801' station. In a next step, make the same plot for each station.\n",
    "\n",
    "<details><summary>Hints</summary>\n",
    "\n",
    "- Add a column `weekend` defining if a value of the index is in the weekend (i.e. days of the week 5 and 6) or not\n",
    "- Add a column `hour` with the hour of the day for each row.\n",
    "- You can `groupby` on multiple items at the same time.\n",
    " \n",
    "</details>\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "nbtutor-solution"
    ]
   },
   "outputs": [],
   "source": [
    "data['weekend'] = data.index.dayofweek.isin([5, 6])\n",
    "data['weekend'] = data['weekend'].replace({True: 'weekend', False: 'weekday'})\n",
    "data['hour'] = data.index.hour"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "nbtutor-solution"
    ]
   },
   "outputs": [],
   "source": [
    "data_weekend = data.groupby(['weekend', 'hour']).mean()\n",
    "data_weekend.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "nbtutor-solution"
    ]
   },
   "outputs": [],
   "source": [
    "# using unstack and pandas plotting\n",
    "data_weekend_BETR801 = data_weekend['BETR801'].unstack(level=0)\n",
    "data_weekend_BETR801.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "nbtutor-solution"
    ]
   },
   "outputs": [],
   "source": [
    "# using a tidy dataset and seaborn\n",
    "data_weekend_BETR801_tidy = data_weekend['BETR801'].reset_index()\n",
    "\n",
    "sns.lineplot(data=data_weekend_BETR801_tidy, x=\"hour\", y=\"BETR801\", hue=\"weekend\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "nbtutor-solution"
    ]
   },
   "outputs": [],
   "source": [
    "# tidy dataset that still includes all stations\n",
    "\n",
    "data_weekend_tidy = pd.melt(data_weekend.reset_index(), id_vars=['weekend', 'hour'],\n",
    "                            var_name='station', value_name='no2')\n",
    "data_weekend_tidy.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "nbtutor-solution"
    ]
   },
   "outputs": [],
   "source": [
    "# when still having multiple factors, it becomes useful to convert to tidy dataset and use seaborn\n",
    "sns.relplot(data=data_weekend_tidy, x=\"hour\", y=\"no2\", kind=\"line\",\n",
    "            hue=\"weekend\", col=\"station\", col_wrap=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "Remove the temporary columns 'hour' and 'weekend' used in the solution of previous exercise:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "data = data.drop(['hour', 'weekend'], axis=1, errors=\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "<div class=\"alert alert-success\">\n",
    "\n",
    "__EXERCISE__\n",
    "\n",
    "Calculate the correlation between the different stations (check in the documentation, google \"pandas correlation\" or use the magic function <code>%psearch</code>)\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "nbtutor-solution"
    ]
   },
   "outputs": [],
   "source": [
    "data[['BETR801', 'BETN029', 'FR04037', 'FR04012']].corr()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "<div class=\"alert alert-success\">\n",
    "\n",
    "__EXERCISE__\n",
    "\n",
    "Count the number of exceedances of hourly values above the European limit 200 µg/m3 for each year and station after 2005. Make a barplot of the counts. Add an horizontal line indicating the maximum number of exceedances (which is 18) allowed per year?\n",
    "\n",
    "<details><summary>Hints</summary>\n",
    " \n",
    "- Create a new DataFrame, called <code>exceedances</code>, (with boolean values) indicating if the threshold is exceeded or not\n",
    "- Remember that the sum of True values can be used to count elements\n",
    "- Adding a horizontal line can be done with the matplotlib function <code>ax.axhline</code>\n",
    " \n",
    "</details>\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "nbtutor-solution"
    ]
   },
   "outputs": [],
   "source": [
    "exceedances = data > 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "nbtutor-solution"
    ]
   },
   "outputs": [],
   "source": [
    "# group by year and count exceedances (sum of boolean)\n",
    "exceedances = exceedances.groupby(exceedances.index.year).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "nbtutor-solution"
    ]
   },
   "outputs": [],
   "source": [
    "# Make a barplot of the yearly number of exceedances\n",
    "ax = exceedances.loc[2005:].plot(kind='bar')\n",
    "ax.axhline(18, color='k', linestyle='--')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# More advanced exercises..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "data = alldata['1999':].copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "<div class=\"alert alert-success\">\n",
    "\n",
    "__EXERCISE__\n",
    "    \n",
    "Perform the following actions for the station `'FR04012'` only:\n",
    "\n",
    "- Remove the rows containing <code>NaN</code> or zero values\n",
    "- Sort the values  of the rows according to the air quality values (low to high values)\n",
    "- Rescale the values to the range [0-1] and store result as <code>FR_scaled</code> (Hint: check <a href=\"https://en.wikipedia.org/wiki/Feature_scaling#Rescaling\">wikipedia</a>)\n",
    "- Use pandas to plot these values sorted, not taking into account the dates\n",
    "- Add the station name 'FR04012' as y-label\n",
    "- [OPTIONAL] Add a vertical line to the plot where the line (hence, the values of variable FR_scaled) reach the value <code>0.3</code>. You will need the documentation of <code>np.searchsorted</code> and matplotlib's <code>axvline</code>\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "nbtutor-solution"
    ]
   },
   "outputs": [],
   "source": [
    "FR_station = data['FR04012'] # select the specific data series\n",
    "FR_station = FR_station[(FR_station.notnull()) & (FR_station != 0.0)]  # exclude the Nan and zero values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "nbtutor-solution"
    ]
   },
   "outputs": [],
   "source": [
    "FR_sorted = FR_station.sort_values(ascending=True)\n",
    "FR_scaled = (FR_sorted - FR_sorted.min())/(FR_sorted.max() - FR_sorted.min())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "nbtutor-solution"
    ]
   },
   "outputs": [],
   "source": [
    "fig, axfr = plt.subplots()\n",
    "FR_scaled.plot(use_index=False, ax = axfr)  #alternative version: FR_scaled.reset_index(drop=True).plot(use_index=False)  \n",
    "axfr.set_ylabel('FR04012')\n",
    "# optional addition, just in case you need this\n",
    "axfr.axvline(x=FR_scaled.searchsorted(0.3), color='0.6', linestyle='--', linewidth=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "<div class=\"alert alert-success\">\n",
    "\n",
    "__EXERCISE__\n",
    "\n",
    "- Create a Figure with two subplots (axes), for which both ax<b>i</b>s are shared\n",
    "- In the left subplot, plot the histogram (30 bins) of station 'BETN029', only for the year 2009\n",
    "- In the right subplot, plot the histogram (30 bins) of station 'BETR801', only for the year 2009\n",
    "- Add the title representing the station name on each of the subplots, you do not want to have a legend\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "nbtutor-solution"
    ]
   },
   "outputs": [],
   "source": [
    "# Mixing an matching matplotlib and Pandas\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, \n",
    "                               sharex=True, \n",
    "                               sharey=True)\n",
    "\n",
    "data.loc['2009', ['BETN029', 'BETR801']].plot(kind='hist', subplots=True, \n",
    "                                              bins=30, legend=False, \n",
    "                                              ax=(ax1, ax2))\n",
    "ax1.set_title('BETN029')\n",
    "ax2.set_title('BETR801')\n",
    "# Remark: the width of the bins is calculated over the x data range for both plots together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "nbtutor-solution"
    ]
   },
   "outputs": [],
   "source": [
    "# A more step by step approach (equally valid)\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, sharey=True, sharex=True)\n",
    "data.loc['2009', 'BETN029'].plot(kind='hist', bins=30, ax=ax1)\n",
    "ax1.set_title('BETN029')\n",
    "data.loc['2009', 'BETR801'].plot(kind='hist', bins=30, ax=ax2)\n",
    "ax2.set_title('BETR801')\n",
    "# Remark: the width of the bins is calculated over the x data range for each plot individually"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "<div class=\"alert alert-success\">\n",
    "\n",
    "__EXERCISE__\n",
    "\n",
    "- Make a selection of the original dataset of the data in January 2009, call the resulting variable <code>subset</code>\n",
    "- Add a new column, called 'dayofweek', to the variable <code>subset</code> which defines for each data point the day of the week\n",
    "- From the <code>subset</code> DataFrame, select only Monday (= day 0) and Sunday (=day 6) and remove the others (so, keep this as variable <code>subset</code>)\n",
    "- Change the values of the dayofweek column in <code>subset</code> according to the following mapping: <code>{0:\"Monday\", 6:\"Sunday\"}</code>\n",
    "- With seaborn, make a scatter plot of the measurements at 'BETN029' vs 'FR04037', with the color variation based on the weekday. Add a linear regression to this plot.\n",
    "\n",
    "**Note**: If you run into the **SettingWithCopyWarning** and do not know what to do, recheck [pandas_03b_indexing](pandas_03b_indexing.ipynb)\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "nbtutor-solution"
    ]
   },
   "outputs": [],
   "source": [
    "subset = data.loc['2009-01'].copy()\n",
    "subset[\"dayofweek\"] = subset.index.dayofweek\n",
    "subset = subset[subset['dayofweek'].isin([0, 6])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "nbtutor-solution"
    ]
   },
   "outputs": [],
   "source": [
    "subset[\"dayofweek\"] = subset[\"dayofweek\"].replace(to_replace={0:\"Monday\", 6:\"Sunday\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "nbtutor-solution"
    ]
   },
   "outputs": [],
   "source": [
    "sns.set_style(\"whitegrid\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "nbtutor-solution"
    ]
   },
   "outputs": [],
   "source": [
    "sns.lmplot(\n",
    "    data=subset, x=\"BETN029\", y=\"FR04037\", hue=\"dayofweek\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "<div class=\"alert alert-success\">\n",
    "\n",
    "__EXERCISE__\n",
    "\n",
    "The maximum daily, 8 hour mean, should be below 100 µg/m³. What is the number of exceedances of this limit for each year/station?\n",
    "  \n",
    "<details><summary>Hints</summary>\n",
    " \n",
    "- Have a look at the `rolling` method to perform moving window operations.\n",
    "\n",
    "</details>\n",
    "\n",
    "<br>_Note:_\n",
    "This is not an actual limit for NO$_2$, but a nice exercise to introduce the `rolling` method. Other pollutans, such as 0$_3$ have actually such kind of limit values based on 8-hour means.\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "nbtutor-solution"
    ]
   },
   "outputs": [],
   "source": [
    "exceedances = data.rolling(8).mean().resample('D').max() > 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "nbtutor-solution"
    ]
   },
   "outputs": [],
   "source": [
    "exceedances = exceedances.groupby(exceedances.index.year).sum()\n",
    "ax = exceedances.plot(kind='bar')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "<div class=\"alert alert-success\">\n",
    "\n",
    "__EXERCISE__\n",
    "\n",
    "Visualize the typical week profile for station 'BETR801' as boxplots (where the values in one boxplot are the <i>daily means</i> for the different <i>weeks</i> for a certain day of the week).\n",
    "\n",
    "\n",
    "<details><summary>Hints</summary>\n",
    " \n",
    "The boxplot method of a DataFrame expects the data for the different boxes in different columns. For this, you can either use `pivot_table` or a combination of `groupby` and `unstack`\n",
    "\n",
    "</details>\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "Calculating daily means and add day of the week information:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "nbtutor-solution"
    ]
   },
   "outputs": [],
   "source": [
    "data_daily = data.resample('D').mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "nbtutor-solution"
    ]
   },
   "outputs": [],
   "source": [
    "# add a dayofweek column\n",
    "data_daily['dayofweek'] = data_daily.index.dayofweek\n",
    "data_daily.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "Plotting with seaborn:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "nbtutor-solution"
    ]
   },
   "outputs": [],
   "source": [
    "# seaborn\n",
    "sns.boxplot(data=data_daily, x='dayofweek', y='BETR801', color=\"grey\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "Reshaping and plotting with pandas:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "nbtutor-solution"
    ]
   },
   "outputs": [],
   "source": [
    "# when using pandas to plot, the different boxplots should be different columns\n",
    "# therefore, pivot table so that the weekdays are the different columns\n",
    "data_daily['week'] = data_daily.index.isocalendar().week\n",
    "data_pivoted = data_daily.pivot_table(columns='dayofweek', index='week',\n",
    "                                      values='BETR801')\n",
    "data_pivoted.head()\n",
    "data_pivoted.boxplot();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "nbtutor-solution"
    ]
   },
   "outputs": [],
   "source": [
    "# An alternative method using `groupby` and `unstack`\n",
    "data_daily.groupby(['dayofweek', 'week'])['BETR801'].mean().unstack(level=0).boxplot();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Nbtutor - export exercises",
  "jupytext": {
   "formats": "ipynb,md:myst"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  },
  "nav_menu": {},
  "toc": {
   "navigate_menu": true,
   "number_sections": true,
   "sideBar": true,
   "threshold": 6,
   "toc_cell": false,
   "toc_section_display": "block",
   "toc_window_display": true
  },
  "toc_position": {
   "height": "860px",
   "left": "0px",
   "right": "1657px",
   "top": "106px",
   "width": "212px"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
