{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p><font size=\"6\"><b>CASE - Observation data</b></font></p>\n",
    "\n",
    "> *Â© 2024, Joris Van den Bossche and Stijn Van Hoey  (<mailto:jorisvandenbossche@gmail.com>, <mailto:stijnvanhoey@gmail.com>). Licensed under [CC BY 4.0 Creative Commons](http://creativecommons.org/licenses/by/4.0/)*\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "plt.style.use('seaborn-v0_8-whitegrid')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Observation data of species (when and where is a given species observed) is typical in biodiversity studies. Large international initiatives support the collection of this data by volunteers, e.g. [iNaturalist](https://www.inaturalist.org/). Thanks to initiatives like [GBIF](https://www.gbif.org/), a lot of these data is also openly available. \n",
    "\n",
    "In this example, data originates from a [study](http://esapubs.org/archive/ecol/E090/118/metadata.htm) of a Chihuahuan desert ecosystem near Portal, Arizona. It is a long-term observation study in 24 different plots (each plot identified with a `verbatimLocality` identifier) and defines, apart from the species, location and date of the observations, also the sex and the weight (if available).\n",
    "\n",
    "The data consists of two data sets:\n",
    "\n",
    "1. `observations.csv` the individual observations.\n",
    "2. `species_names.csv` the overview list of the species names.\n",
    "\n",
    "Let's start with the observations data!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading in the observations data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\">\n",
    "\n",
    "**EXERCISE**\n",
    "\n",
    "- Read in the `data/observations.csv` file with Pandas and assign the resulting DataFrame to a variable with the name `observations`.\n",
    "- Make sure the 'occurrenceID' column is used as the index of the resulting DataFrame while reading in the data set.\n",
    "- Inspect the first five rows of the DataFrame and the data types of each of the data columns.\n",
    "\n",
    "<details><summary>Hints</summary>\n",
    "    \n",
    "- All read functions in Pandas start with `pd.read_...`.\n",
    "- Setting a column as index can be done with an argument of the `read_csv` function To check the documentation of a function, use the keystroke combination of SHIFT + TAB when the cursor is on the function.\n",
    "- Remember `.head()` and `.info()`?\n",
    "    \n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "nbtutor-solution"
    ]
   },
   "outputs": [],
   "source": [
    "observations = pd.read_csv(\"data/observations.csv\", index_col=\"occurrenceID\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    },
    "tags": [
     "nbtutor-solution"
    ]
   },
   "outputs": [],
   "source": [
    "observations.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    },
    "tags": [
     "nbtutor-solution"
    ]
   },
   "outputs": [],
   "source": [
    "observations.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\">\n",
    "\n",
    "**EXERCISE**\n",
    "\n",
    "Create a new column with the name `eventDate` which contains datetime-aware information of each observation. To do so, combine the columns `day`, `month` and `year` into a datetime-aware data type by using the `pd.to_datetime` function from Pandas (check the help of that function to see how multiple columns with the year, month and day can be converted).\n",
    "\n",
    "<details><summary>Hints</summary>\n",
    "\n",
    "- `pd.to_datetime` can automatically combine the information from multiple columns. To select multiple columns, use a list of column names, e.g. `df[[\"my_col1\", \"my_col2\"]]`\n",
    "- To create a new column, assign the result to new name, e.g. `df[\"my_new_col\"] = df[\"my_col\"] + 1`\n",
    "    \n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    },
    "tags": [
     "nbtutor-solution"
    ]
   },
   "outputs": [],
   "source": [
    "observations[\"eventDate\"] =  pd.to_datetime(observations[[\"year\", \"month\", \"day\"]])\n",
    "observations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\">\n",
    "\n",
    "**EXERCISE**\n",
    "\n",
    "For convenience when this dataset will be combined with other datasets, add a new column, `datasetName`, to the survey data set with `\"Ecological Archives E090-118-D1.\"` as value for each of the individual records (static value for the entire data set)\n",
    "\n",
    "<details><summary>Hints</summary>\n",
    "\n",
    "- When a column does not exist, a new `df[\"a_new_column\"]` can be created by assigning a value to it.\n",
    "- Pandas will automatically broadcast a single string value to each of the rows in the DataFrame.\n",
    "    \n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "nbtutor-solution"
    ]
   },
   "outputs": [],
   "source": [
    "observations[\"datasetName\"] = \"Ecological Archives E090-118-D1.\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cleaning the `verbatimSex` column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "observations[\"verbatimSex\"].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the further analysis (and the species concerned in this specific data set), the `sex` information should be either `male` or `female`. We want to create a new column, named `sex` and convert the current values to the corresponding sex, taking into account the following mapping:\n",
    "* `M` -> `male`\n",
    "* `F` -> `female`\n",
    "* `R` -> `male`\n",
    "* `P` -> `female`\n",
    "* `Z` -> nan"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\">\n",
    "\n",
    "**EXERCISE**\n",
    "\n",
    "- Express the mapping of the values (e.g. `M` -> `male`) into a Python dictionary object with the variable name `sex_dict`. `Z` values correspond to _Not a Number_, which can be defined as `np.nan`. \n",
    "- Use the `sex_dict` dictionary to replace the values in the `verbatimSex` column to the new values and save the mapped values in a new column 'sex' of the DataFrame.\n",
    "- Check the conversion by printing the unique values within the new column `sex`.\n",
    "\n",
    "<details><summary>Hints</summary>\n",
    "    \n",
    "- A dictionary is a Python standard library data structure, see https://docs.python.org/3/tutorial/datastructures.html#dictionaries - no Pandas magic involved when you need a key/value mapping.\n",
    "- When you need to replace values, look for the Pandas method `replace`.    \n",
    "    \n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "nbtutor-solution"
    ]
   },
   "outputs": [],
   "source": [
    "sex_dict = {\"M\": \"male\",\n",
    "            \"F\": \"female\",\n",
    "            \"R\": \"male\",\n",
    "            \"P\": \"female\",\n",
    "            \"Z\": np.nan}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "nbtutor-solution"
    ]
   },
   "outputs": [],
   "source": [
    "observations['sex'] = observations['verbatimSex'].replace(sex_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    },
    "tags": [
     "nbtutor-solution"
    ]
   },
   "outputs": [],
   "source": [
    "observations[\"sex\"].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tackle missing values (NaN) and duplicate values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "See [pandas_07_missing_values.ipynb](pandas_07_missing_values.ipynb) for an overview of functionality to work with missing values."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\">\n",
    "\n",
    "**EXERCISE**\n",
    "\n",
    "How many records in the data set have no information about the `species_ID`? Use the `isna()` method to find out.\n",
    "\n",
    "<details><summary>Hints</summary>\n",
    "\n",
    "- Do NOT use `survey_data_processed['species_ID'] == np.nan`, but use the available method `isna()` to check if a value is NaN\n",
    "- The result of an (element-wise) condition returns a set of True/False values, corresponding to 1/0 values. The amount of True values is equal to the sum.\n",
    "    \n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    },
    "tags": [
     "nbtutor-solution"
    ]
   },
   "outputs": [],
   "source": [
    "observations['species_ID'].isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\">\n",
    "\n",
    "**EXERCISE**\n",
    "\n",
    "How many duplicate records are present in the dataset? Use the method `duplicated()` to check if a row is a duplicate.\n",
    "\n",
    "<details><summary>Hints</summary>\n",
    "    \n",
    "- The result of an (element-wise) condition returns a set of True/False values, corresponding to 1/0 values. The amount of True values is equal to the sum.\n",
    "    \n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    },
    "tags": [
     "nbtutor-solution"
    ]
   },
   "outputs": [],
   "source": [
    "observations.duplicated().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\">\n",
    "\n",
    "**EXERCISE**\n",
    "\n",
    "- Select all duplicate data by filtering the `observations` data and assign the result to a new variable `duplicate_observations`. The `duplicated()` method provides a `keep` argument define which duplicates (if any) to mark.\n",
    "- Sort the `duplicate_observations` data on both the columns `eventDate` and `verbatimLocality` and show the first 9 records.\n",
    "\n",
    "<details><summary>Hints</summary>\n",
    "\n",
    "- Check the documentation of the `duplicated` method to find out which value the argument `keep` requires to select all duplicate data.\n",
    "- `sort_values()` can work with a single columns name as well as a list of names.\n",
    "\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    },
    "tags": [
     "nbtutor-solution"
    ]
   },
   "outputs": [],
   "source": [
    "duplicate_observations = observations[observations.duplicated(keep=False)]\n",
    "duplicate_observations.sort_values([\"eventDate\", \"verbatimLocality\"]).head(9)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\">\n",
    "\n",
    "**EXERCISE**\n",
    "\n",
    "- Exclude the duplicate values (i.e. keep the first occurrence while removing the other ones) from the `observations` data set and save the result as `observations_unique`. Use the `drop duplicates()` method from Pandas.\n",
    "- How many observations are still left in the data set?    \n",
    "\n",
    "<details><summary>Hints</summary>\n",
    "\n",
    "- `keep=First` is the default option for `drop_duplicates`\n",
    "- The number of rows in a DataFrame is equal to the `len`gth\n",
    "\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "nbtutor-solution"
    ]
   },
   "outputs": [],
   "source": [
    "observations_unique = observations.drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    },
    "tags": [
     "nbtutor-solution"
    ]
   },
   "outputs": [],
   "source": [
    "len(observations_unique)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\">\n",
    "\n",
    "**EXERCISE**\n",
    "\n",
    "Use the `dropna()` method to find out:    \n",
    "\n",
    "- For how many observations (rows) we have all the information available (i.e. no NaN values in any of the columns)? \n",
    "- For how many observations (rows) we do have the `species_ID` data available ? \n",
    "- Remove the data without `species_ID` data from the observations and assign the result to a new variable `observations_with_ID`\n",
    "\n",
    "<details><summary>Hints</summary>\n",
    "\n",
    "- `dropna` by default removes by default all rows for which _any_ of the columns contains a `NaN` value.\n",
    "- To specify which specific columns to check, use the `subset` argument\n",
    "\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    },
    "tags": [
     "nbtutor-solution"
    ]
   },
   "outputs": [],
   "source": [
    "len(observations_unique.dropna())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    },
    "tags": [
     "nbtutor-solution"
    ]
   },
   "outputs": [],
   "source": [
    "len(observations_unique.dropna(subset=['species_ID']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    },
    "tags": [
     "nbtutor-solution"
    ]
   },
   "outputs": [],
   "source": [
    "observations_with_ID = observations_unique.dropna(subset=['species_ID'])\n",
    "observations_with_ID.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\">\n",
    "\n",
    "**EXERCISE**\n",
    "\n",
    "Filter the  `observations` data and select only those records that do not have a `species_ID` while having information on the `sex`. Store the result as variable `not_identified`.\n",
    "\n",
    "<details><summary>Hints</summary>\n",
    "\n",
    "- To combine logical operators element-wise in Pandas, use the `&` operator.\n",
    "- Pandas provides both a `isna()` and a `notna()` method to check the existence of `NaN` values.\n",
    "\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "nbtutor-solution"
    ]
   },
   "outputs": [],
   "source": [
    "mask = observations['species_ID'].isna() & observations['sex'].notna()\n",
    "not_identified = observations[mask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    },
    "tags": [
     "nbtutor-solution"
    ]
   },
   "outputs": [],
   "source": [
    "not_identified.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Species abundance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\">\n",
    "\n",
    "**EXERCISE**\n",
    "\n",
    "Which 8 species (use the `name` column to identify the different species) have been observed most over the entire data set?\n",
    "\n",
    "<details><summary>Hints</summary>\n",
    "\n",
    "- Pandas provide a function to combine sorting and showing the first n records, see [here](https://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.nlargest.html)...\n",
    "    \n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    },
    "tags": [
     "nbtutor-solution"
    ]
   },
   "outputs": [],
   "source": [
    "observations.groupby(\"name\").size().nlargest(8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    },
    "tags": [
     "nbtutor-solution"
    ]
   },
   "outputs": [],
   "source": [
    "observations['name'].value_counts().iloc[:8]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\">\n",
    "\n",
    "**EXERCISE**\n",
    "\n",
    "- What is the number of different species (`name`) in each of the `verbatimLocality` plots? Use the `nunique` method. Assign the output to a new variable `n_species_per_plot`.\n",
    "- Define a Matplotlib `Figure` (`fig`) and `Axes` (`ax`) to prepare a plot. Make an horizontal bar chart using Pandas `plot` function linked to the just created Matplotlib `ax`. Each bar represents the `species per plot/verbatimLocality`. Change the y-label to 'Plot number'.\n",
    "\n",
    "<details><summary>Hints</summary>\n",
    "\n",
    "- _...in each of the..._ should provide a hint to use `groupby` for this exercise. The `nunique` is the aggregation function for each of the groups.\n",
    "- `fig, ax = plt.subplots()` prepares a Matplotlib Figure and Axes.\n",
    "    \n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "nbtutor-solution"
    ]
   },
   "outputs": [],
   "source": [
    "n_species_per_plot = observations.groupby([\"verbatimLocality\"])[\"name\"].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    },
    "tags": [
     "nbtutor-solution"
    ]
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(6, 6))\n",
    "n_species_per_plot.plot(kind=\"barh\", ax=ax)\n",
    "ax.set_ylabel(\"Plot number\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "nbtutor-solution"
    ]
   },
   "outputs": [],
   "source": [
    "## Alternative option to calculate the species per plot:\n",
    "## inspired on the pivot table we already had:\n",
    "#species_per_plot = observations.reset_index().pivot_table(\n",
    "#      index=\"species_ID\", columns=\"verbatimLocality\", values=\"occurrenceID\", aggfunc='count')\n",
    "#n_species_per_plot = species_per_plot.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\">\n",
    "\n",
    "**EXERCISE**\n",
    "\n",
    "- What is the number of plots (`verbatimLocality`) each of the species (`name`) have been observed in? Assign the output to a new variable `n_plots_per_species`. Sort the counts from low to high.\n",
    "- Make an horizontal bar chart using Pandas `plot` function to show the number of plots each of the species was found (using the `n_plots_per_species` variable).  \n",
    "\n",
    "<details><summary>Hints</summary>\n",
    "\n",
    "- Use the previous exercise to solve this one.\n",
    "    \n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    },
    "tags": [
     "nbtutor-solution"
    ]
   },
   "outputs": [],
   "source": [
    "n_plots_per_species = observations.groupby([\"name\"])[\"verbatimLocality\"].nunique().sort_values()\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10, 8))\n",
    "n_plots_per_species.plot(kind=\"barh\", ax=ax)\n",
    "ax.set_xlabel(\"Number of plots\");\n",
    "ax.set_ylabel(\"\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\">\n",
    "\n",
    "**EXERCISE**\n",
    "\n",
    "- Starting from the `observations`, calculate the amount of males and females present in each of the plots (`verbatimLocality`). The result should return the counts for each of the combinations of `sex` and `verbatimLocality`. Assign to a new variable `n_plot_sex` and ensure the counts are in a column named \"count\".\n",
    "- Use a `pivot()` to convert the `n_plot_sex` DataFrame to a new DataFrame with the `verbatimLocality` as index and `male`/`female` as column names. Assign to a new variable `pivoted`.\n",
    "\n",
    "<details><summary>Hints</summary>\n",
    "\n",
    "- _...for each of the combinations..._ `groupby` can also be used with multiple columns at the same time.\n",
    "- If a `groupby` operation gives a Series as result, you can give that Series a name with the `.rename(..)` method.\n",
    "- `reset_index()` is useful function to convert multiple indices into columns again.\n",
    "    \n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    },
    "tags": [
     "nbtutor-solution"
    ]
   },
   "outputs": [],
   "source": [
    "n_plot_sex = observations.groupby([\"sex\", \"verbatimLocality\"]).size().rename(\"count\").reset_index()\n",
    "n_plot_sex.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    },
    "tags": [
     "nbtutor-solution"
    ]
   },
   "outputs": [],
   "source": [
    "pivoted = n_plot_sex.pivot(columns=\"sex\", index=\"verbatimLocality\", values=\"count\")\n",
    "pivoted.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As such, we can use the variable `pivoted` to plot the result:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "pivoted.plot(kind='bar', figsize=(12, 6), rot=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\">\n",
    "\n",
    "**EXERCISE**\n",
    "\n",
    "Recreate the previous plot with the `catplot` function from the Seaborn library directly starting from <code>observations</code> DataFrame. \n",
    "\n",
    "<details><summary>Hints</summary>\n",
    "\n",
    "- Check the `kind` argument of the `catplot` function to find out how to use counts to define the bars instead of a `y` value.\n",
    "- To link a column to different colors, use the `hue` argument\n",
    "- Using `height` and `aspect`, the figure size can be optimized.\n",
    "\n",
    "    \n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    },
    "tags": [
     "nbtutor-solution"
    ]
   },
   "outputs": [],
   "source": [
    "sns.catplot(data=observations, x=\"verbatimLocality\", \n",
    "            hue=\"sex\", kind=\"count\", height=3, aspect=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\">\n",
    "\n",
    "**EXERCISE**\n",
    "\n",
    "- Create a table, called `heatmap_prep`, based on the `observations` DataFrame with the row index the individual years, in the column the months of the year (1-> 12) and as values of the table, the counts for each of these year/month combinations.\n",
    "- Using the seaborn <a href=\"http://seaborn.pydata.org/generated/seaborn.heatmap.html\">documentation</a>, make a heatmap starting from the `heatmap_prep` variable.\n",
    "\n",
    "<details><summary>Hints</summary>\n",
    "\n",
    "- A `pivot_table` has an `aggfunc` parameter by which the aggregation of the cells combined into the year/month element are combined (e.g. mean, max, count,...). \n",
    "- You can use the `species_ID` to count the number of observations.\n",
    "- seaborn has an `heatmap` function which requires a short-form DataFrame, comparable to giving each element in a table a color value.\n",
    "    \n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    },
    "tags": [
     "nbtutor-solution"
    ]
   },
   "outputs": [],
   "source": [
    "heatmap_prep = observations.pivot_table(index='year', columns='month', \n",
    "                                        values=\"species_ID\", aggfunc='count')\n",
    "fig, ax = plt.subplots(figsize=(10, 8))\n",
    "ax = sns.heatmap(heatmap_prep, cmap='Reds')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adding the names of the observed species"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Recap from previous exercises - remove duplicates and observations without species information\n",
    "observations_unique_ = observations.drop_duplicates()\n",
    "observations_data = observations_unique_.dropna(subset=['species_ID'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the data set `observations`, the column `specied_ID` provides an identifier and the `name` column the species name. The taxonomic information of each speciess is provided in a separate file `species_names.csv`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "species_names = pd.read_csv(\"data/species_names.csv\")\n",
    "species_names.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The species names contains for each identifier in the `ID` column the scientific name and taxonomic information of a species. The `species_names` data set contains in total 38 different scientific names:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "species_names.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For further analysis, let's combine both in a single DataFrame in the following exercise."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\">\n",
    "\n",
    "**EXERCISE**\n",
    "\n",
    "Combine the DataFrames `observations_data` and `species_names` by adding the corresponding species name information (class, kingdom,..) to the individual observations using the `pd.merge()` function. Assign the output to a new variable `survey_data`. Use the `species_ID` to combine the both DataFrames.\n",
    "\n",
    "<details><summary>Hints</summary>\n",
    "\n",
    "- This is an example of a database JOIN operation. Pandas provides the `pd.merge` function to join two data sets using a common identifier.\n",
    "- Take into account that our key-column is different for `observations` and `species_names`, respectively `specied_ID` and `ID`. The `pd.merge()` function has `left_on` and `right_on` keywords to specify the name of the column in the left and right `DataFrame` to merge on.\n",
    "    \n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    },
    "tags": [
     "nbtutor-solution"
    ]
   },
   "outputs": [],
   "source": [
    "survey_data = pd.merge(observations_data, species_names, how=\"left\",\n",
    "                       left_on=\"species_ID\", right_on=\"ID\")\n",
    "survey_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Select subsets according to taxa of species"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "survey_data['taxa'].value_counts()\n",
    "#survey_data.groupby('taxa').size()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\">\n",
    "\n",
    "**EXERCISE**\n",
    "\n",
    "- Select the observations for which the `taxa` is equal to 'Rabbit', 'Bird' or 'Reptile'. Assign the result to a variable `non_rodent_species`. Use the `isin` method for the selection.\n",
    "\n",
    "<details><summary>Hints</summary>\n",
    "\n",
    "- You do not have to combine three different conditions, but use the `isin` operator with a list of names.\n",
    "    \n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "nbtutor-solution"
    ]
   },
   "outputs": [],
   "source": [
    "non_rodent_species = survey_data[survey_data['taxa'].isin(['Rabbit', 'Bird', 'Reptile'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    },
    "tags": [
     "nbtutor-solution"
    ]
   },
   "outputs": [],
   "source": [
    "len(non_rodent_species)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\">\n",
    "\n",
    "**EXERCISE**\n",
    "\n",
    "Select the observations for which the `name` starts with the characters 'r' (make sure it does not matter if a capital character is used in the 'taxa' name). Call the resulting variable `r_species`.\n",
    "\n",
    "<details><summary>Hints</summary>\n",
    "\n",
    "- Remember the `.str.` construction to provide all kind of string functionalities? You can combine multiple of these after each other.\n",
    "- If the presence of capital letters should not matter, make everything lowercase first before comparing (`.lower()`)    \n",
    "    \n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "nbtutor-solution"
    ]
   },
   "outputs": [],
   "source": [
    "r_species = survey_data[survey_data['name'].str.lower().str.startswith('r')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    },
    "tags": [
     "nbtutor-solution"
    ]
   },
   "outputs": [],
   "source": [
    "len(r_species)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "r_species[\"name\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\">\n",
    "\n",
    "**EXERCISE**\n",
    "\n",
    "Select the observations that are not Birds. Call the resulting variable <code>non_bird_species</code>.\n",
    "\n",
    "<details><summary>Hints</summary>\n",
    "\n",
    "- Logical operators like `==`, `!=`, `>`,... can still be used.\n",
    "    \n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "nbtutor-solution"
    ]
   },
   "outputs": [],
   "source": [
    "non_bird_species = survey_data[survey_data['taxa'] != 'Bird']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "len(non_bird_species)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\">\n",
    "\n",
    "**EXERCISE**\n",
    "\n",
    "Select the __Bird__ (taxa is Bird) observations from 1985-01 till 1989-12 usint the `eventDate` column. Call the resulting variable `birds_85_89`.\n",
    "\n",
    "<details><summary>Hints</summary>\n",
    "\n",
    "- No hints, you can do this! (with the help of some `<=` and `&`, and don't forget the put brackets around each comparison that you combine)\n",
    "    \n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    },
    "tags": [
     "nbtutor-solution"
    ]
   },
   "outputs": [],
   "source": [
    "birds_85_89 = survey_data[(survey_data[\"eventDate\"] >= \"1985-01-01\")\n",
    "                          & (survey_data[\"eventDate\"] <= \"1989-12-31 23:59\")\n",
    "                          & (survey_data['taxa'] == 'Bird')]\n",
    "birds_85_89.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    },
    "tags": [
     "nbtutor-solution"
    ]
   },
   "outputs": [],
   "source": [
    "# alternative solution\n",
    "birds_85_89 = survey_data[(survey_data[\"eventDate\"].dt.year >= 1985)\n",
    "                          & (survey_data[\"eventDate\"].dt.year <= 1989) \n",
    "                          & (survey_data['taxa'] == 'Bird')]\n",
    "birds_85_89.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\">\n",
    "\n",
    "**EXERCISE**\n",
    "\n",
    "- Drop the observations for which no `weight` information is available.\n",
    "- On the filtered data, compare the median weight for each of the species (use the `name` column)\n",
    "- Sort the output from high to low median weight (i.e. descending)\n",
    "    \n",
    "__Note__ You can do this all in a single line statement, but don't have to do it as such!\n",
    "\n",
    "<details><summary>Hints</summary>    \n",
    "\n",
    "- You will need `dropna`, `groupby`, `median` and `sort_values`.\n",
    "    \n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    },
    "tags": [
     "nbtutor-solution"
    ]
   },
   "outputs": [],
   "source": [
    "# Multiple lines\n",
    "obs_with_weight = survey_data.dropna(subset=[\"weight\"])\n",
    "median_weight = obs_with_weight.groupby(['name'])[\"weight\"].median()\n",
    "median_weight.sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    },
    "tags": [
     "nbtutor-solution"
    ]
   },
   "outputs": [],
   "source": [
    "# Single line statement\n",
    "survey_data.dropna(subset=[\"weight\"]).groupby(['name'])[\"weight\"].median().sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remark that we started from a `tidy` data format (also called *long* format) and converted to *short* format with in the row index the years, in the column the months and the counts for each of these year/month combinations as values."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\">\n",
    "\n",
    "**EXERCISE**\n",
    "\n",
    "- Make a summary table with the number of records of each of the species in each of the plots (called `verbatimLocality`)? Each of the species `name`s is a row index and each of the `verbatimLocality` plots is a column name.\n",
    "- Use the Seaborn <a href=\"http://seaborn.pydata.org/generated/seaborn.heatmap.html\">documentation</a> to make a heatmap.\n",
    "\n",
    "<details><summary>Hints</summary>\n",
    "\n",
    "- Make sure to pass the correct columns to respectively the `index`, `columns`, `values` and `aggfunc` parameters of the `pivot_table` function. You can use the `ID` to count the number of observations for each name/locality combination (when counting rows, the exact column doesn't matter).\n",
    "\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    },
    "tags": [
     "nbtutor-solution"
    ]
   },
   "outputs": [],
   "source": [
    "species_per_plot = survey_data.reset_index().pivot_table(index=\"name\", \n",
    "                                                         columns=\"verbatimLocality\", \n",
    "                                                         values=\"ID\", \n",
    "                                                         aggfunc='count')\n",
    "species_per_plot.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    },
    "tags": [
     "nbtutor-solution"
    ]
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(8,8))\n",
    "sns.heatmap(species_per_plot, ax=ax, cmap='Greens')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\">\n",
    "\n",
    "**EXERCISE**\n",
    "\n",
    "Make a plot visualizing the evolution of the number of observations for each of the individual __years__ (i.e. annual counts) using the `resample` method.\n",
    "\n",
    "<details><summary>Hints</summary>\n",
    "\n",
    "- You want to `resample` the data using the `eventDate` column to create annual counts. If the index is not a datetime-index, you can use the `on=` keyword to specify which datetime column to use.\n",
    "- `resample` needs an aggregation function on how to combine the values within a single 'group' (in this case data within a year). In this example, we want to know the `size` of each group, i.e. the number of records within each year.\n",
    "    \n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    },
    "tags": [
     "nbtutor-solution"
    ]
   },
   "outputs": [],
   "source": [
    "survey_data.resample('A', on='eventDate').size().plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (OPTIONAL SECTION) Evolution of species during monitoring period"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*In this section, all plots can be made with the embedded Pandas plot function, unless specificly asked*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\">\n",
    "\n",
    "**EXERCISE**\n",
    "\n",
    "Plot using Pandas `plot` function the number of records for `Dipodomys merriami` for each month of the year (January (1) -> December (12)), aggregated over all years.\n",
    "\n",
    "<details><summary>Hints</summary>\n",
    "\n",
    "- _...for each month of..._ requires `groupby`. \n",
    "- `resample` is not useful here, as we do not want to change the time-interval, but look at month of the year (over all years)\n",
    "    \n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "nbtutor-solution"
    ]
   },
   "outputs": [],
   "source": [
    "merriami = survey_data[survey_data[\"name\"] == \"Dipodomys merriami\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    },
    "tags": [
     "nbtutor-solution"
    ]
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "merriami.groupby(merriami['eventDate'].dt.month).size().plot(kind=\"barh\", ax=ax)\n",
    "ax.set_xlabel(\"number of occurrences\")\n",
    "ax.set_ylabel(\"Month of the year\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\">\n",
    "\n",
    "**EXERCISE**\n",
    "\n",
    "Plot, for the species 'Dipodomys merriami', 'Dipodomys ordii', 'Reithrodontomys megalotis' and 'Chaetodipus baileyi', the monthly number of records as a function of time for the whole monitoring period. Plot each of the individual species in a separate subplot and provide them all with the same y-axis scale\n",
    "\n",
    "<details><summary>Hints</summary>\n",
    "\n",
    "- `isin` is useful to select from within a list of elements.\n",
    "- `groupby` AND `resample` need to be combined. We do want to change the time-interval to represent data as a function of time (`resample`) and we want to do this _for each name/species_ (`groupby`). The order matters!\n",
    "- `unstack` is a Pandas function a bit similar to `pivot`. Check the [unstack documentation](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.unstack.html) as it might be helpful for this exercise.\n",
    "    \n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "nbtutor-solution"
    ]
   },
   "outputs": [],
   "source": [
    "subsetspecies = survey_data[survey_data[\"name\"].isin(['Dipodomys merriami', 'Dipodomys ordii',\n",
    "                                                      'Reithrodontomys megalotis', 'Chaetodipus baileyi'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "nbtutor-solution"
    ]
   },
   "outputs": [],
   "source": [
    "month_evolution = subsetspecies.groupby(\"name\").resample('M', on='eventDate').size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    },
    "tags": [
     "nbtutor-solution"
    ]
   },
   "outputs": [],
   "source": [
    "species_evolution = month_evolution.unstack(level=0)\n",
    "axs = species_evolution.plot(subplots=True, figsize=(14, 8), sharey=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\">\n",
    "\n",
    "**EXERCISE**\n",
    "\n",
    "Recreate the same plot as in the previous exercise using Seaborn `relplot` functon with the `month_evolution` variable.\n",
    "\n",
    "<details><summary>Hints</summary>\n",
    "\n",
    "- We want to have the `counts` as a function of `eventDate`, so link these columns to y and x respectively.\n",
    "- To create subplots in Seaborn, the usage of _facetting_ (splitting data sets to multiple facets) is used by linking a column name to the `row`/`col` parameter. \n",
    "- Using `height` and `aspect`, the figure size can be optimized.\n",
    "    \n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Given as solution..\n",
    "subsetspecies = survey_data[survey_data[\"name\"].isin(['Dipodomys merriami', 'Dipodomys ordii',\n",
    "                                                      'Reithrodontomys megalotis', 'Chaetodipus baileyi'])]\n",
    "month_evolution = subsetspecies.groupby(\"name\").resample('M', on='eventDate').size().rename(\"counts\")\n",
    "month_evolution = month_evolution.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    },
    "tags": [
     "nbtutor-solution"
    ]
   },
   "outputs": [],
   "source": [
    "sns.relplot(data=month_evolution, x='eventDate', y=\"counts\", \n",
    "            row=\"name\", kind=\"line\", hue=\"name\", height=2, aspect=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\">\n",
    "\n",
    "**EXERCISE**\n",
    "\n",
    "Plot the annual amount of occurrences for each of the 'taxa' as a function of time using Seaborn. Plot each taxa in a separate subplot and do not share the y-axis among the facets.\n",
    "\n",
    "<details><summary>Hints</summary>\n",
    "\n",
    "- Combine `resample` and `groupby`!\n",
    "- Check out the previous exercise for the plot function.\n",
    "- Pass the `sharey=False` to the `facet_kws` argument as a dictionary.\n",
    "    \n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "nbtutor-solution"
    ]
   },
   "outputs": [],
   "source": [
    "year_evolution = survey_data.groupby(\"taxa\").resample('A', on='eventDate').size()\n",
    "year_evolution.name = \"counts\"\n",
    "year_evolution = year_evolution.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    },
    "tags": [
     "nbtutor-solution"
    ]
   },
   "outputs": [],
   "source": [
    "year_evolution.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    },
    "tags": [
     "nbtutor-solution"
    ]
   },
   "outputs": [],
   "source": [
    "sns.relplot(data=year_evolution, x='eventDate', y=\"counts\", \n",
    "            col=\"taxa\", col_wrap=2, kind=\"line\", height=2, aspect=5, \n",
    "            facet_kws={\"sharey\": False})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\">\n",
    "\n",
    "**EXERCISE**\n",
    "\n",
    "The observations where taken by volunteers. You wonder on which day of the week the most observations where done. Calculate for each day of the week (`weekday`) the number of observations and make a barplot.\n",
    "\n",
    "<details><summary>Hints</summary>\n",
    "\n",
    "- Did you know the Python standard Library has a module `calendar` which contains names of week days, month names,...?\n",
    "\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    },
    "tags": [
     "nbtutor-solution"
    ]
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "survey_data.groupby(survey_data[\"eventDate\"].dt.weekday).size().plot(kind='barh', color='#66b266', ax=ax)\n",
    "\n",
    "import calendar\n",
    "xticks = ax.set_yticklabels(calendar.day_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nice work!"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Nbtutor - export exercises",
  "jupytext": {
   "formats": "ipynb,md:myst"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  },
  "nav_menu": {},
  "toc": {
   "navigate_menu": true,
   "number_sections": true,
   "sideBar": true,
   "threshold": 6,
   "toc_cell": false,
   "toc_section_display": "block",
   "toc_window_display": true
  },
  "toc-autonumbering": false,
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
