{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a4812285-6a36-429e-835d-5c5584c9e9e2",
   "metadata": {},
   "source": [
    "<p><font size=\"6\"><b>06 - Pandas: Methods for data cleaning</b></font></p>\n",
    "\n",
    "> *Â© 2024, Joris Van den Bossche and Stijn Van Hoey  (<mailto:jorisvandenbossche@gmail.com>, <mailto:stijnvanhoey@gmail.com>). Licensed under [CC BY 4.0 Creative Commons](http://creativecommons.org/licenses/by/4.0/)*\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90802025-748e-4f6e-b26f-0c76c786e49c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02d8cdab-3d12-42ae-a997-cfcd99f418a2",
   "metadata": {},
   "source": [
    "A number of Pandas functions are useful when cleaning up raw data and converting it to a data set ready for analysis and visualisation. In this notebook a selection of methods are introduced:\n",
    "\n",
    "- `drop`\n",
    "- `rename`\n",
    "- `replace`\n",
    "- `explode`\n",
    "- `drop_duplicates`/`duplicates`\n",
    "- `astype`\n",
    "- `unique`\n",
    "- `.str.`-methods\n",
    "\n",
    "__Note:__ Working with _missing values_ is tackled in a dedicated notebook [pandas_07_missing_values](./pandas_07_missing_values.ipynb)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e97721c-253f-4f25-bd32-7b9c1e97806c",
   "metadata": {},
   "source": [
    "We showcase using a _dirty_ example data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74f85056-b3f1-4c79-9ebd-ee9a0309f0c8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "countries = pd.DataFrame({'county name': ['Belgium', 'Flance', 'Germany', 'Netherlands', ['United Kingdom', 'Germany']],\n",
    "                          'population': [11.3, 64.3, 81.3, 16.9, 64.9],\n",
    "                          'area': [30510, 671308, 357050, 41526, [244820, np.nan]],\n",
    "                          'capital': ['Brussels', ' Paris         ', 'Barlin', 'Amsterdam', 'London']})\n",
    "countries"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6cdf333-68d3-4465-9882-4823e277a52e",
   "metadata": {},
   "source": [
    "## `drop`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "171c3ac6-818d-462e-948f-d46bc9ec10d6",
   "metadata": {},
   "source": [
    "Drop columns (or rows) by name (this can also be achieved by selecting the columns you want to keep, but if you only want to drop a few columns, `drop()` is easier). Specify a list of column names to drop:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f453823-28f0-4a50-bcc0-e52d731f0461",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "countries.drop(columns=[\"area\", \"capital\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73b36bfe-8bc0-44c6-b428-437948119ddd",
   "metadata": {},
   "source": [
    "## `rename`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe9c002a-46c7-4071-8c42-209c22def4bf",
   "metadata": {},
   "source": [
    "Use a `dict` with the dictionary keys the old column/index name and the dictionary values the new column/index name:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fa011ea-567f-400a-a200-e6ab060f63fc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "countries = countries.rename(columns={\"county name\": \"country\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c13529ed-882a-445f-ac15-cac7a205883c",
   "metadata": {},
   "source": [
    "## `replace`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91ec7c37-f40a-4d2a-bc90-e374f82e8148",
   "metadata": {},
   "source": [
    "Replace values in a column. Different inputs can be used. The most basic one is providing a value `to_replace` and a new `value`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2534e99-574e-411b-9dad-1e2bce088d43",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "countries[\"capital\"].replace(\"Barlin\", \"Berlin\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1099b12d-d5ba-4d81-b6c7-8d7851c60cd4",
   "metadata": {},
   "source": [
    "Similar to `rename`, one can use a `dict` with the dictionary keys the old data and the dictionary values the new data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f82b5b7f-50b6-4ef8-a7ce-41c45aae61df",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "countries = countries.replace({\"Barlin\": \"Berlin\", \"Flance\": \"France\"})\n",
    "countries"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5555d90c-a704-41e9-a293-00e3618a5edf",
   "metadata": {},
   "source": [
    "## `explode`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b59ae2c1-4ab4-4d66-80c6-d5b9ddba5204",
   "metadata": {},
   "source": [
    "[`explode`](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.explode.html) multiple values in a cell to individual records (rows). Not regularly required, but very powerful when in case:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ced4c48f-443b-421f-9c67-e3695213774a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "countries_exploded = countries.explode([\"country\", \"area\"])\n",
    "countries_exploded"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95e6ebaa-de35-4ad8-a489-c3e82d758ec1",
   "metadata": {},
   "source": [
    "## `drop_duplicates`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "265e968e-b9f4-47bf-8498-20252be66850",
   "metadata": {},
   "source": [
    "Checking duplicate values in a data set with [`duplicated`](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.duplicated.html) or remove duplicate values with [`drop_duplicates`](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.drop_duplicates.html):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c16e5068-77c9-480d-a38d-68809a070335",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "countries_exploded.duplicated(subset=[\"country\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c44e00e3-ce22-49a9-bba0-1638e119f336",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "countries_exploded = countries_exploded.drop_duplicates(subset=[\"country\"], keep=\"first\").copy()  # More on this copy later\n",
    "countries_exploded"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51a6c735-177b-4781-98d0-ab0a8da3b4b4",
   "metadata": {},
   "source": [
    "## `astype`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fd380de-35c0-4067-8d58-e38d0ad2a6b5",
   "metadata": {},
   "source": [
    "Pandas read functions might not always use the most appropriate data type for each of the columns. Converting them to a different data type can also improve the memory usage of the DataFrame (e.g. `int16` versus `float64`). The [`astype` ](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.astype.html) method supports data type conversion to both [Numpy data types](https://numpy.org/doc/stable/user/basics.types.html) as well as [Pandas specific data types](https://pandas.pydata.org/docs/user_guide/basics.html#dtypes)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7cbd21b-5534-4546-8992-d291c6ab2e74",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "countries_exploded.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5ea90e1-c7e8-4478-b6bb-b8185baa1a64",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "countries_exploded[\"area\"] = countries_exploded[\"area\"].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e815f85-9ba3-4518-af7b-84f63652e653",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "countries_exploded.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69700729-4c69-4915-b553-bdfb1057023b",
   "metadata": {},
   "source": [
    "## `unique`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13bb810a-ebbd-4a59-a156-1f5d44d283c8",
   "metadata": {},
   "source": [
    "Working with larger data sets, knowing which values are in a column:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eca4ed82-6be2-4a35-9ad3-2c500cdd8e5f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "countries_exploded[\"capital\"].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94871b4a-63ec-4639-9569-29f617dde75f",
   "metadata": {},
   "source": [
    "## `.str.`-methods"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c958af1-5289-454a-ad30-0e64946e6029",
   "metadata": {},
   "source": [
    "Noticed the redundant spaces in the capital column? \n",
    "\n",
    "Whereas `replace` could work for this specific case (it also accepts _regular expressions_):\n",
    "\n",
    "```python\n",
    "countries_exploded[\"capital\"].replace(r\"^\\s+|\\s+\", \"\", regex=True)\n",
    "```\n",
    "\n",
    "Pandas provides a set of convenient __string__ methods to handle these (element-wise) cleaning of strings, each of them accessible with the `.str.` accessor (e.g. `str.split`, `str.startswith`, `removeprefix`):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "275fce29-55a2-4992-8c2b-01fd709762ae",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "countries_exploded[\"capital\"] = countries_exploded[\"capital\"].str.strip()\n",
    "countries_exploded[\"capital\"].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "116ffaf6-f2c7-4569-8092-874280f27e28",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\">\n",
    "    \n",
    "__INFO__\n",
    "\n",
    "For an overview of the available `.str.`-methods, see https://pandas.pydata.org/docs/user_guide/text.html#method-summary\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4163319d-2d5b-4e17-babc-04c134e66bac",
   "metadata": {},
   "source": [
    "## Exercises: application on a real dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0ae559d-88f2-48c5-b6d3-fa579bdc9d48",
   "metadata": {},
   "source": [
    "For these exercises, we will use data of road casualties in Belgium in 2020 [made available by statbel](https://statbel.fgov.be/en/open-data/road-casualties-2020). The [metadata](https://statbel.fgov.be/sites/default/files/files/opendata/Verkeersslachtoffers/TF_ACCIDENTS_VICTIMS_META.xlsx) is available as well as a reference. The data contains the number of victims due to road causalities:\n",
    "\n",
    "- `MS_VCT`: Number of victims\n",
    "- `MS_VIC_OK`: Number of uninjured\n",
    "- `MS_SLY_INJ`: Number of slightly injured\n",
    "- `MS_SERLY_INJ`: Number of severely injured\n",
    "- `MS_MORY_INJ`: Number of mortally injured\n",
    "- `MS_DEAD`: Number of dead\n",
    "- `MS_DEAD_30_DAYS`: Number of dead after 30 days\n",
    "\n",
    "Together with metadata about date and time, the victim and road type, light conditions, location,...\n",
    "\n",
    "Pandas can load the data directly from the `zip`-file :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a55bbde-0a4f-4c7c-90a4-42324e69a647",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "casualties_raw = pd.read_csv(\"./data/TF_ACCIDENTS_VICTIMS_2020.zip\", \n",
    "                         compression='zip', \n",
    "                         sep=\"|\", \n",
    "                         low_memory=False)\n",
    "casualties_raw.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f348c30-a8a4-4905-b230-0df46b5d3533",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\">\n",
    "    \n",
    "__INTERMEZZO - display options__\n",
    "\n",
    "Pandas provides a number of configurable settings to display data, for example `display.max_rows`, `display.precision` and `display.max_columns`. When exploring a new data set, adjusting the `display.max_columns` setting is of particular interest to be able to scroll the full data set.\n",
    "    \n",
    "See https://pandas.pydata.org/docs/user_guide/options.html#options-and-settings for the documentation and an [overview of the available settings](https://pandas.pydata.org/docs/user_guide/options.html#available-options)\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "341e9cb4-9507-4e0c-a5e6-b5e7524bcd70",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "pd.options.display.max_columns = 45"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "649719e5-2c8f-460f-8bd3-57920ac779c2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "casualties_raw.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4186cdd7-a1d2-45d7-b8dc-dfe90d7fc1e2",
   "metadata": {},
   "source": [
    "Whereas the data is already well organised and structured, some adjustments are required to support further analysis:\n",
    "\n",
    "- Combine the day and hour into a single datetime-aware data type.\n",
    "- Clean up the column names.\n",
    "- Metadata is always provided both in Dutch and French.\n",
    "- ...\n",
    "\n",
    "Let's apply the cleaning methods to clean up the data in the next set of exercises."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db3a7681-3aab-4782-bb92-6053f4d7fc6a",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\">\n",
    "\n",
    "**EXERCISE**\n",
    "\n",
    "Check the unique values of the `TX_SEX_DESCR_NL` column.\n",
    "\n",
    "Based on the the values, create a mapping dictionary to replace the values with the english version (`\"Mannelijk\" -> \"male\", \"Vrouwelijk\" -> \"female\"`). Use `None` for the unknown values (`Onbekend` in Dutch). Apply the mapping to overwrite the values in the `TX_SEX_DESCR_NL` column with the new value.\n",
    "\n",
    "<details><summary>Hints</summary>\n",
    "    \n",
    "- Create the mapping by hand and define a Python dictionary.\n",
    "- Use the `replace()` method to update the values of the `TX_SEX_DESCR_NL` column. You can call this method on the column (Series object).\n",
    "\n",
    "</details>\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa05c085-0c06-411b-b392-8a0d690de235",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "casualties_raw[\"TX_SEX_DESCR_NL\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3e5934f-9a1c-402b-9a2e-dc984ce3eb12",
   "metadata": {
    "tags": [
     "nbtutor-solution"
    ]
   },
   "outputs": [],
   "source": [
    "casualties_raw[\"TX_SEX_DESCR_NL\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e72ec39e-6a74-4cf9-9daa-b0f0d495d3d5",
   "metadata": {
    "tags": [
     "nbtutor-solution"
    ]
   },
   "outputs": [],
   "source": [
    "gender_mapping = {\"Vrouwelijk\": \"female\", \"Mannelijk\": \"male\", \"Onbekend\": None}\n",
    "casualties_raw[\"TX_SEX_DESCR_NL\"] = casualties_raw[\"TX_SEX_DESCR_NL\"].replace(gender_mapping)\n",
    "casualties_raw[\"TX_SEX_DESCR_NL\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06b91dbf-a860-41c2-ac17-4f80948e65cb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "casualties_raw[\"TX_SEX_DESCR_NL\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fbd73d8-dbf1-494a-abaa-23b95b4e6bcd",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\">\n",
    "\n",
    "**EXERCISE**\n",
    "\n",
    "Check the unique values of the `DT_HOUR` column. Which of the data values is used as _not a number_ (not known)? Verify the amount of records that for which `DT_HOUR` is not known.\n",
    "    \n",
    "A check with the data provider confirmed that the record(s) with value 99 did actually happen at 9 AM and are a typo instead of _not a number_ replacement value. Replace the 99 values with the real hour of the day in the `DT_HOUR` column.\n",
    "\n",
    "<details><summary>Hints</summary>\n",
    "    \n",
    "- The number `99` is not a valid hour of the day and used as _not a number_ data point.\n",
    "- Only one data record has an unknown hour of the day.\n",
    "- Remember the `replace()` method that we used in the previous exercise. We can again provide a mapping, or in this case of only replacing a single value, you can also provide the original value and new value as two positional arguments.\n",
    "\n",
    "</details>\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad7457a2-6213-434c-9348-d5cb14827dab",
   "metadata": {
    "tags": [
     "nbtutor-solution"
    ]
   },
   "outputs": [],
   "source": [
    "casualties_raw[\"DT_HOUR\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "182ae250-d575-42d7-83b1-da92ea89e5d3",
   "metadata": {
    "tags": [
     "nbtutor-solution"
    ]
   },
   "outputs": [],
   "source": [
    "(casualties_raw[\"DT_HOUR\"] == 99).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b6803b5-21c6-47d4-89c4-f7cea4825458",
   "metadata": {
    "tags": [
     "nbtutor-solution"
    ]
   },
   "outputs": [],
   "source": [
    "casualties_raw[\"DT_HOUR\"] = casualties_raw[\"DT_HOUR\"].replace(99, 9)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18981bfc-b811-4ea3-8bba-4207c120cc6b",
   "metadata": {
    "tags": []
   },
   "source": [
    "<div class=\"alert alert-info\">\n",
    "    \n",
    "__INTERMEZZO__ - List comprehensions\n",
    "\n",
    "A [list comprehension](https://docs.python.org/3/glossary.html#term-list-comprehension) is a compact way to process all or part of the elements, comparable to a for-loop, in a sequence and return a list.\n",
    "    \n",
    "For example, the code in the following example:\n",
    "    \n",
    "```python\n",
    "example = [2, 3, 4]\n",
    "updated_example = []\n",
    "for element in example:\n",
    "    updated_example.append(element*2)\n",
    "```    \n",
    "\n",
    "will produce the same result `updated_example=[4, 6, 8]` as:\n",
    "\n",
    "```python\n",
    "updated_example = [element*2 for element in example]\n",
    "```\n",
    "    \n",
    "The latter is a __list comprehension__, which is a more compact way of writing the for-loop to return the updated list.\n",
    "    \n",
    "The loop can also contain an if-statement, e.g.\n",
    "    \n",
    "```python\n",
    "example = [2, 3, 4]\n",
    "updated_example = []\n",
    "for element in example:\n",
    "    if element != 3:\n",
    "        updated_example.append(element*2)\n",
    "```\n",
    "\n",
    "and\n",
    "\n",
    "```python\n",
    "updated_example = [element*2 for element in example if element != 3]\n",
    "```\n",
    "    \n",
    "will both result in `[4, 8]`.   \n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a53992d-7a51-4526-8d29-184a058d79a7",
   "metadata": {
    "tags": []
   },
   "source": [
    "<div class=\"alert alert-success\">\n",
    "\n",
    "**EXERCISE**\n",
    "\n",
    "Remove all the `_FR` metadata columns  from the `casualties_raw` data set and assign the result to a new variable `casualties_nl`. Use the `column_names_with_fr` variable derived in the next cell to remove the columns.\n",
    "\n",
    "<details><summary>Hints</summary>\n",
    "    \n",
    "- Remove columns with the `drop()` method. The method works with one or more column names.\n",
    "- Make sure to explicitly set the `columns=` parameter.\n",
    "\n",
    "__NOTE__ The `column_names_with_fr` variable is created using the `df.columns` attribute of the DataFrame:\n",
    "- Instead of enlisting the column names manually, a [list comprehension](https://docs.python.org/3/tutorial/datastructures.html#list-comprehensions) - a _feature of standard Python_ - is used to select the columns names ending on `_FR`. Loop over the column names in `casualties_raw.columns`.\n",
    "- Within the list comprehension, the [`endswith()`](https://docs.python.org/3/library/stdtypes.html#str.endswith) standard string method is used to check if a column name ends on `_FR`. \n",
    "- ! Pandas also provides the `.str.endswith()` method, but this is for the data values inside a DataFrame. In this exercise we want to adjust the column names itself.    \n",
    "    \n",
    "</details>\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0ab5728-1ca1-4629-a521-d82a1c649ed5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "column_names_with_fr = [col for col in casualties_raw.columns if col.endswith(\"_FR\")]\n",
    "column_names_with_fr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a331f51d-ede8-4ced-96a0-daff7d9244c5",
   "metadata": {
    "tags": [
     "nbtutor-solution"
    ]
   },
   "outputs": [],
   "source": [
    "casualties_nl = casualties_raw.drop(columns=column_names_with_fr)\n",
    "casualties_nl"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a293a59-a41f-414a-af35-7f76c11ce8af",
   "metadata": {
    "tags": []
   },
   "source": [
    "<div class=\"alert alert-success\">\n",
    "\n",
    "**EXERCISE**\n",
    "\n",
    "A number of the remaining metadata columns names have the `TX_` and the `_DESCR_NL` in the column name. Clean up these column names by removing the `TX_` at the start and the `_DESCR_NL` at the end of the column names using the helper function `clean_column_name` defined in the next cell. Update the `casualties_nl` variable, assign the result to the variable `casualties`.\n",
    "\n",
    "<details><summary>Hints</summary>\n",
    "    \n",
    "- Use the `rename` method and apply the mapping on the `columns`.\n",
    "- The input of the `rename` method van be a dictionary or a function. Use the `clean_column_name` as the function to rename the columns. \n",
    "- Make sure to explicitly set the columns= parameter.    \n",
    "    \n",
    "__NOTE__ The function `clean_column_name` takes as input a string and returns the string after removing the prefix and suffix. \n",
    "\n",
    "- The pandas method `rename` applies this function to each column name individually.    \n",
    "- `removeprefix()` and `removesuffix()` are [Python string methods](https://docs.python.org/3/library/stdtypes.html#string-methods) to remove start/trailing characters if present.\n",
    "\n",
    "</details>\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04b2ec07-79f1-44eb-9b6b-6c7568f4da9f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def clean_column_name(name):\n",
    "    return name.removeprefix(\"TX_\").removesuffix(\"_DESCR_NL\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5839e1c3-66c1-4258-a163-37ed69d31e18",
   "metadata": {
    "tags": [
     "nbtutor-solution"
    ]
   },
   "outputs": [],
   "source": [
    "casualties = casualties_nl.rename(columns=clean_column_name)\n",
    "casualties.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e070510e-2696-4369-9db3-78a0c535bebc",
   "metadata": {
    "tags": []
   },
   "source": [
    "<div class=\"alert alert-success\">\n",
    "\n",
    "**EXERCISE**\n",
    "\n",
    "The day (`DT_DAY`) and hour (`DT_HOUR`) are two separate columns instead of a single `datetime` data type column. \n",
    "    \n",
    "- Check the data types of the `DT_DAY` and `DT_HOUR` columns.\n",
    "- Combine the two columns into a single column (using _string concatenation_) and use the `pd.to_datetime` function to convert the combined column (call the new column `\"datetime\"`).\n",
    "\n",
    "<details><summary>Hints</summary>\n",
    "    \n",
    "- The data type of columns is available as the `dtypes` attribute.\n",
    "- String concatenation is done element-wise in pandas using the `+` operator. Do not forget to convert the `DT_HOUR` column into a `str` column using the `astype()` before trying to concatenate it with the day.\n",
    "\n",
    "</details>\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "183b0eb0-360d-43f8-9299-99b9a01e1e66",
   "metadata": {
    "tags": [
     "nbtutor-solution"
    ]
   },
   "outputs": [],
   "source": [
    "casualties[[\"DT_DAY\", \"DT_HOUR\"]].dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a3ee3b5-e3b9-459b-9563-0cb8e160cb00",
   "metadata": {
    "tags": [
     "nbtutor-solution"
    ]
   },
   "outputs": [],
   "source": [
    "casualties[\"datetime\"] = casualties[\"DT_DAY\"] + \" \" + casualties[\"DT_HOUR\"].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5b01320-f2d0-434c-aad1-b6794f6c64a7",
   "metadata": {
    "tags": [
     "nbtutor-solution"
    ]
   },
   "outputs": [],
   "source": [
    "casualties[\"datetime\"] = pd.to_datetime(casualties[\"datetime\"])\n",
    "casualties[\"datetime\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15b15255-ee92-45bc-bbf1-f6ee1919c5a9",
   "metadata": {
    "tags": []
   },
   "source": [
    "<div class=\"alert alert-success\">\n",
    "\n",
    "**EXERCISE**\n",
    "\n",
    "For columns consisting of a limited number of categories with (_ordinal data_) or without a logical order, Pandas has a specific data type: `Categorical`. An example in the data set is the `DAY_OF_WEEK` (from `Monday` -> `Sunday`). \n",
    "    \n",
    "For this conversion, the `astype` is not sufficient. Use the `pd.Categorical` function (check the documentation) to create a new column `week_day` with the week days defined as a Categorical variable. Use Monday as the first day of the week and make sure the categories are ordered.\n",
    "\n",
    "<details><summary>Hints</summary>\n",
    "    \n",
    "- See [Pandas categorical info](https://pandas.pydata.org/pandas-docs/stable/user_guide/categorical.html#object-creation) for more information\n",
    "- Use `ordered=True` to define ordered data.  \n",
    "\n",
    "</details>\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfa89cbb-943b-4449-8acf-e3e15e287dd6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Conversion to english weekday names\n",
    "casualties[\"DAY_OF_WEEK\"] = casualties[\"DAY_OF_WEEK\"].replace({\"maandag\": \"Monday\", \n",
    "                                                               \"dinsdag\": \"Tuesday\", \n",
    "                                                               \"woensdag\": \"Wednesday\", \n",
    "                                                               \"donderdag\": \"Thursday\", \n",
    "                                                               \"vrijdag\": \"Friday\", \n",
    "                                                               \"zaterdag\": \"Saturday\", \n",
    "                                                               \"zondag\": \"Sunday\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "457ac0f6-b88a-45a4-a83c-6a70eae1bdbf",
   "metadata": {
    "tags": [
     "nbtutor-solution"
    ]
   },
   "outputs": [],
   "source": [
    "casualties[\"week_day\"] = pd.Categorical(casualties[\"DAY_OF_WEEK\"], \n",
    "                                        categories=[\"Monday\", \"Tuesday\", \"Wednesday\", \"Thursday\", \n",
    "                                                    \"Friday\", \"Saturday\", \"Sunday\"], \n",
    "                                        ordered=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ce91077-c29f-4fa5-a62d-85040cb2a42a",
   "metadata": {
    "tags": [
     "nbtutor-solution"
    ]
   },
   "outputs": [],
   "source": [
    "casualties[\"week_day\"].dtype"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35284dca-0c5f-45a9-9763-3fb89d1be981",
   "metadata": {
    "tags": []
   },
   "source": [
    "<div class=\"alert alert-success\">\n",
    "\n",
    "**(OPTIONAL) EXERCISE**\n",
    "\n",
    "In the `AGE_CLS` column, the age is formatted as `X tot Y jaar` (i.e. _x till y year_). Remove the Dutch description and convert the data into a format `Y - Y` to define the age classes. \n",
    "    \n",
    "Use the string methods as much as possible. The `Onbekend`, `  ` (empty string) and `75 jaar en meer` data values can be done by direct replacement into `None`, `None` and `> 75` respectively.\n",
    "\n",
    "<details><summary>Hints</summary>\n",
    "    \n",
    "- Use the `.str.replace()` (note the difference with the Pandas `replace()` method) and the `str.removesuffix()` methods to convert the data format.\n",
    "- Add an additional `str.strip` to get rid of the spaces and the 'unknown' number of spaces in the empty string case.\n",
    "- Using the `replace()` method with a dictionary just works for the remaining two values:  `{\"Onbekend\": None, \"75 jaar en meer\": \">75\"}`. It will leave other values (not specified in the dictionary) as is.\n",
    "\n",
    "</details>\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73ac4269-14ee-4de2-a626-056e32cc015d",
   "metadata": {
    "tags": [
     "nbtutor-solution"
    ]
   },
   "outputs": [],
   "source": [
    "casualties[\"AGE_CLS\"] = casualties[\"AGE_CLS\"].str.replace(\" tot \", \" - \").str.removesuffix(\" jaar\").str.strip()\n",
    "casualties[\"AGE_CLS\"] = casualties[\"AGE_CLS\"].replace({\"Onbekend\": None, \"75 jaar en meer\": \">75\", \"\": None})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd53d1a8-a62a-4705-a4e3-45bf7caa4843",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# verify outcome\n",
    "casualties[\"AGE_CLS\"].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfa4ada2-b824-4b3e-a016-f53a208ef29e",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\">\n",
    "\n",
    "**(OPTIONAL) EXERCISE**\n",
    "\n",
    "The data set contains the number of victims. The link with the individual accidents is not available in the current data set and multiple records/rows of the data set can belong to a single accident. \n",
    "    \n",
    "We can expect that records with the same day, hour, municipality , light condition, road type and build up area are probably linked to the same accident. Try to estimate the number of accidents.\n",
    "\n",
    "<details><summary>Hints</summary>\n",
    "    \n",
    "- This exercise is a special case of the `drop_duplicates` method. When we drop duplicate records when `\"DT_DAY\", \"DT_HOUR\",  \"CD_MUNTY_REFNIS\", \"BUILD_UP_AREA\",\"LIGHT_COND\", \"ROAD_TYPE\"` are all the same, we have an estimate on the number of accidents.\n",
    "- Use the `subset` parameter to define a specific set of column names.\n",
    "\n",
    "</details>\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58b75469-972e-47ec-becc-c3ccf218e9a1",
   "metadata": {
    "tags": [
     "nbtutor-solution"
    ]
   },
   "outputs": [],
   "source": [
    "unique_combinations = [\"DT_DAY\", \"DT_HOUR\",  \"CD_MUNTY_REFNIS\", \"BUILD_UP_AREA\",\"LIGHT_COND\", \"ROAD_TYPE\"]\n",
    "casualties.drop_duplicates(subset=unique_combinations).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90674ed4-5101-4827-8c53-4ecdecfbfacb",
   "metadata": {
    "tags": [
     "nbtutor-solution"
    ]
   },
   "outputs": [],
   "source": [
    "# alternative using `duplicated`\n",
    "(~casualties.duplicated(subset=unique_combinations)).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1005bc9-6f75-4be9-8275-36d5b9d37682",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
