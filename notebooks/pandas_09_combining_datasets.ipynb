{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "be5c9d31",
   "metadata": {
    "tags": []
   },
   "source": [
    "<p><font size=\"6\"><b>09 - Pandas: Combining datasets</b></font></p>\n",
    "\n",
    "\n",
    "> *© 2025, Joris Van den Bossche and Stijn Van Hoey  (<mailto:jorisvandenbossche@gmail.com>, <mailto:stijnvanhoey@gmail.com>). Licensed under [CC BY 4.0 Creative Commons](http://creativecommons.org/licenses/by/4.0/)*\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce9bb2f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "561ce43c",
   "metadata": {},
   "source": [
    "Combining data is essential functionality in a data analysis workflow. \n",
    "\n",
    "Data is distributed in multiple files, different information needs to be merged, new data is calculated, .. and needs to be added together. Pandas provides various facilities for easily combining together Series and DataFrame objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11476551",
   "metadata": {},
   "outputs": [],
   "source": [
    "# redefining the example objects\n",
    "\n",
    "# series\n",
    "population = pd.Series({'Germany': 81.3, 'Belgium': 11.3, 'France': 64.3, \n",
    "                        'United Kingdom': 64.9, 'Netherlands': 16.9})\n",
    "\n",
    "# dataframe\n",
    "data = {'country': ['Belgium', 'France', 'Germany', 'Netherlands', 'United Kingdom'],\n",
    "        'population': [11.3, 64.3, 81.3, 16.9, 64.9],\n",
    "        'area': [30510, 671308, 357050, 41526, 244820],\n",
    "        'capital': ['Brussels', 'Paris', 'Berlin', 'Amsterdam', 'London']}\n",
    "countries = pd.DataFrame(data)\n",
    "countries"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b858e88f",
   "metadata": {},
   "source": [
    "# Adding columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2b1c6b7",
   "metadata": {},
   "source": [
    "As we already have seen before, adding a single column is very easy:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "485a2fb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "pop_density = countries['population']*1e6 / countries['area']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45edcb7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "pop_density"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c5f2873",
   "metadata": {},
   "outputs": [],
   "source": [
    "countries['pop_density'] = pop_density"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f50f3d14",
   "metadata": {},
   "outputs": [],
   "source": [
    "countries"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c398f5e",
   "metadata": {},
   "source": [
    "Adding multiple columns at once is also possible. For example, the following method gives us a DataFrame of two columns:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10d44b2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "countries[\"country\"].str.split(\" \", expand=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "799437fe",
   "metadata": {},
   "source": [
    "We can add both at once to the dataframe:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "030cb537",
   "metadata": {},
   "outputs": [],
   "source": [
    "countries[['first', 'last']] = countries[\"country\"].str.split(\" \", expand=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8507cdb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "countries"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6463b2d3",
   "metadata": {},
   "source": [
    "# Concatenating data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52e4ca07",
   "metadata": {},
   "source": [
    "The ``pd.concat`` function does all of the heavy lifting of combining data in different ways.\n",
    "\n",
    "``pd.concat`` takes a list or dict of Series/DataFrame objects and concatenates them in a certain direction (`axis`) with some configurable handling of “what to do with the other axes”."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "226f0566",
   "metadata": {},
   "source": [
    "## Combining rows - ``pd.concat``"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22e0d782",
   "metadata": {},
   "source": [
    "![](../img/pandas/schema-concat0.svg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd4e59ea",
   "metadata": {},
   "source": [
    "Assume we have some similar data as in `countries`, but for a set of different countries:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce79b16e-ea96-4845-9104-9a18be4de526",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = {'country': ['Belgium', 'France', 'Germany', 'Netherlands', 'United Kingdom'],\n",
    "        'population': [11.3, 64.3, 81.3, 16.9, 64.9],\n",
    "        'area': [30510, 671308, 357050, 41526, 244820],\n",
    "        'capital': ['Brussels', 'Paris', 'Berlin', 'Amsterdam', 'London']}\n",
    "countries = pd.DataFrame(data)\n",
    "countries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "160524db",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = {'country': ['Nigeria', 'Rwanda', 'Egypt', 'Morocco', ],\n",
    "        'population': [182.2, 11.3, 94.3, 34.4],\n",
    "        'area': [923768, 26338 , 1010408, 710850],\n",
    "        'capital': ['Abuja', 'Kigali', 'Cairo', 'Rabat']}\n",
    "countries_africa = pd.DataFrame(data)\n",
    "countries_africa "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "437438cb",
   "metadata": {},
   "source": [
    "We now want to combine the rows of both datasets:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1ed5209",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.concat([countries, countries_africa])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff42f9db",
   "metadata": {},
   "source": [
    "If we don't want the index to be preserved:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbae6a1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.concat([countries, countries_africa], ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74aa5586",
   "metadata": {},
   "source": [
    "When the two dataframes don't have the same set of columns, by default missing values get introduced:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3115002f",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.concat([countries, countries_africa[['country', 'capital']]], ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5aef5d6",
   "metadata": {},
   "source": [
    "We can also pass a dictionary of objects instead of a list of objects. Now the keys of the dictionary are preserved as an additional index level:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0061f065",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.concat({'europe': countries, 'africa': countries_africa})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b361359f-e464-4094-b16f-fc6dbf22ee6b",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\">\n",
    "\n",
    "**NOTE**:\n",
    "\n",
    "A typical use case of `concat` is when you create (or read) multiple DataFrame with a similar structure in a loop, and then want to combine this list of DataFrames into a single DataFrame.\n",
    "\n",
    "For example, assume you have a folder of similar CSV files (eg the data per day) you want to read and combine, this would look like:\n",
    "\n",
    "```python\n",
    "import pathlib\n",
    "\n",
    "data_files = pathlib.Path(\"data_directory\").glob(\"*.csv\")\n",
    "\n",
    "dfs = []\n",
    "\n",
    "for path in data_files:\n",
    "    temp = pd.read_csv(path)\n",
    "    dfs.append(temp)\n",
    "\n",
    "df = pd.concat(dfs)\n",
    "```\n",
    "<br>\n",
    "Important: append to a list (not DataFrame), and concat this list at the end after the loop!\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "970012f2",
   "metadata": {},
   "source": [
    "# Joining data with `pd.merge`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78e1b973",
   "metadata": {},
   "source": [
    "Using `pd.concat` above, we combined datasets that had the same columns. But, another typical case is where you want to add information of a second dataframe to a first one based on one of the columns they have in common. That can be done with [`pd.merge`](http://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.merge.html).\n",
    "\n",
    "Let's look again at the titanic passenger data, but taking a small subset of it to make the example easier to grasp:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e00931e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"data/titanic.csv\")\n",
    "df = df.loc[:9, ['Survived', 'Pclass', 'Sex', 'Age', 'Fare', 'Embarked']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37dcebb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ae11628",
   "metadata": {},
   "source": [
    "Assume we have another dataframe with more information about the 'Embarked' locations:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35e5b529",
   "metadata": {},
   "outputs": [],
   "source": [
    "locations = pd.DataFrame({'Embarked': ['S', 'C', 'N'],\n",
    "                          'City': ['Southampton', 'Cherbourg', 'New York City'],\n",
    "                          'Country': ['United Kindom', 'France', 'United States']})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94906138",
   "metadata": {},
   "outputs": [],
   "source": [
    "locations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ebb09a0",
   "metadata": {},
   "source": [
    "We now want to add those columns to the titanic dataframe, for which we can use `pd.merge`, specifying the column on which we want to merge the two datasets:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "571b126f",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.merge(df, locations, on='Embarked', how='left')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b1df56c",
   "metadata": {},
   "source": [
    "In this case we use `how='left` (a \"left join\") because we wanted to keep the original rows of `df` and only add matching values from `locations` to it. Other options are 'inner', 'outer' and 'right' (see the [docs](http://pandas.pydata.org/pandas-docs/stable/merging.html#brief-primer-on-merge-methods-relational-algebra) for more on this, or this visualization: https://joins.spathon.com/)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c539a85-f507-4c6e-8bca-cca2717e57dc",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Exercise with VAT numbers\n",
    "\n",
    "For this exercise, we start from an open dataset on *\"Enterprises subject to VAT\"* (VAT = Value Added Tax), from https://statbel.fgov.be/en/open-data/enterprises-subject-vat-according-legal-form-11. For different regions and different enterprise types, it contains the number of enterprises subset to VAT (\"MS_NUM_VAT\"), and the number of such enterprises that started (\"MS_NUM_VAT_START\") or stopped (\"MS_NUM_VAT_STOP\") in 2019.\n",
    "\n",
    "This file is provided as a zipped archive of a SQLite database file. Let's first unzip it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04d4c9c7-5ebd-466c-ad6d-be2c41ad437b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import zipfile\n",
    "\n",
    "with zipfile.ZipFile(\"data/TF_VAT_NACE_SQ_2019.zip\", \"r\") as zip_ref:\n",
    "    zip_ref.extractall()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c33cadec-5a2d-457a-8a2a-504095e710d2",
   "metadata": {},
   "source": [
    "SQLite (https://www.sqlite.org/index.html) is a light-weight database engine, and a database can be stored as a single file. With the `sqlite3` module of the Python standard library, we can open such a database and inspect it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2722fb9-dfa5-46c5-b19b-57b27e3f48f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sqlite3\n",
    "\n",
    "# connect with the database file\n",
    "con = sqlite3.connect(\"TF_VAT_NACE_2019.sqlite\")\n",
    "# list the tables that are present in the database\n",
    "con.execute(\"SELECT name FROM sqlite_master WHERE type='table';\").fetchall()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72e3d928-6076-43bc-8acc-c64b4f550c20",
   "metadata": {},
   "source": [
    "Pandas provides functionality to query data from a database. Let's fetch the main dataset contained in this file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f883e9af-29d5-4eea-87a6-0eeb7bcb80e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_sql(\"SELECT * FROM TF_VAT_NACE_2019\", con)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbc875b4-84a8-4422-9a73-d864ae7951ba",
   "metadata": {},
   "source": [
    "More information about the identifyer variables (the first three columns) can be found in the other tables. For example, the \"CD_LGL_PSN_VAT\" column contains information about the legal form of the enterprise. What the values in this column mean, can be found in a different table:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d9669a6-0997-4b27-85dd-2c424fc01a25",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_legal_forms = pd.read_sql(\"SELECT * FROM TD_LGL_PSN_VAT\", con)\n",
    "df_legal_forms"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9d98b0e-3ada-4649-b3ff-8bd077ec4e3e",
   "metadata": {},
   "source": [
    "This type of data organization is called a **\"star schema\"** (https://en.wikipedia.org/wiki/Star_schema), and if we want to get the a \"denormalized\" version of the main dataset (all the data combined), we need to join the different tables."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b104def0-f6d8-4b8b-a6a3-79ae6fb2253a",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\">\n",
    "\n",
    "**EXERCISE 1**:\n",
    "\n",
    "Add the full name of the legal form (in the DataFrame `df_legal_forms`) to the main dataset (`df`). For this, join both datasets based on the \"CD_LGL_PSN_VAT\" column.\n",
    "    \n",
    "<details><summary>Hints</summary>\n",
    "\n",
    "- `pd.merge` requires a left and a right DataFrame, the specification `on` to define the common index and the merge type `how`. \n",
    "- Decide which type of merge is most appropriate: left, right, inner,...\n",
    "\n",
    "</details>      \n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0b8a88b-1325-4a14-9e8d-4575ee736180",
   "metadata": {
    "tags": [
     "nbtutor-solution"
    ]
   },
   "outputs": [],
   "source": [
    "# %load _solutions/pandas_09_combining_datasets1.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6eacbea1-3dbb-4477-aec7-37b622fe79ed",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\">\n",
    "\n",
    "**EXERCISE 2**:\n",
    "\n",
    "How many registered enterprises are there for each legal form? Sort the result from most to least occurring form.\n",
    "\n",
    "<details><summary>Hints</summary>\n",
    "\n",
    "- To count the number of registered enterprises, take the `sum` _for each_ (`groupby`) legal form.\n",
    "- Check the `ascending` parameter of the `sort_values` function.\n",
    "\n",
    "</details>    \n",
    "    \n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5912d86-7dea-4c4b-a870-d3047067d4ad",
   "metadata": {
    "tags": [
     "nbtutor-solution"
    ]
   },
   "outputs": [],
   "source": [
    "# %load _solutions/pandas_09_combining_datasets2.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab0b08df-2d63-4ef1-b8a5-6d5b46a4dd0b",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\">\n",
    "\n",
    "**EXERCISE 3**:\n",
    "\n",
    "How many enterprises are registered per province?\n",
    "\n",
    "* Read in the \"TD_MUNTY_REFNIS\" table from the database file into a `df_muni` dataframe, which contains more information about the municipality (and the province in which the municipality is located).\n",
    "* Merge the information about the province into the main `df` dataset.\n",
    "* Using the joined dataframe, calculate the total number of registered companies per province.\n",
    "\n",
    "<details><summary>Hints</summary>\n",
    "\n",
    "- Data loading in Pandas requires `pd.read_...`, in this case `read_sql`. Do not forget the connection object as a second input.\n",
    "- `df_muni` contains a lot of columns, whereas we are only interested in the province information. Only use the relevant columns \"TX_PROV_DESCR_EN\" and \"CD_REFNIS\" (you need this to join the data).\n",
    "- Calculate the `sum` _for each_ (`groupby`) province.    \n",
    "    \n",
    "\n",
    "</details>    \n",
    "    \n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d42e1dbb-5797-41be-8a5c-5f3e55d301bd",
   "metadata": {
    "tags": [
     "nbtutor-solution"
    ]
   },
   "outputs": [],
   "source": [
    "# %load _solutions/pandas_09_combining_datasets3.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1926f621-a87e-4128-a493-d818ac1364dc",
   "metadata": {
    "tags": [
     "nbtutor-solution"
    ]
   },
   "outputs": [],
   "source": [
    "# %load _solutions/pandas_09_combining_datasets4.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35d580ab-cbaa-4f78-966e-d921b5ccb54b",
   "metadata": {
    "tags": [
     "nbtutor-solution"
    ]
   },
   "outputs": [],
   "source": [
    "# %load _solutions/pandas_09_combining_datasets5.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "190892e5-2054-4d52-8034-273c3c1d4a7a",
   "metadata": {},
   "source": [
    "## Joining with spatial data to make a map\n",
    "\n",
    "The course materials contains a simplified version of the \"statistical sectors\" dataset (https://statbel.fgov.be/nl/open-data/statistische-sectoren-2019), with the borders of the municipalities. This dataset is provided as a zipped ESRI Shapefile, one of the often used file formats used in GIS for vector data.\n",
    "\n",
    "The [GeoPandas](https://geopandas.org) package extends pandas with geospatial functionality."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3533137a-ce16-4ade-82c7-4333c9e9bbdf",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import geopandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad75058e-b8dd-41d1-a0ea-9c2ad2e8aada",
   "metadata": {},
   "outputs": [],
   "source": [
    "stat = geopandas.read_file(\"data/statbel_statistical_sectors_2019.shp.zip\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "518f5de1-7996-4a6f-b33a-d73d3d182572",
   "metadata": {},
   "outputs": [],
   "source": [
    "stat.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9b64ca6-793c-4b13-add9-4d9cc81368ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "stat.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "135c36ec-9c56-49af-8a58-d635349d088f",
   "metadata": {},
   "source": [
    "The resulting dataframe (a `GeoDataFrame`) has a \"geometry\" column (in this case with polygons representing the borders of the municipalities), and a couple of new methods with geospatial functionality (for example, the `plot()` method by default makes a map). It is still a DataFrame, and everything we have learned about pandas can be used here as well.\n",
    "\n",
    "Let's visualize the change in number of registered enterprises on a map at the municipality-level. \n",
    "\n",
    "We first calculate the total number of (existing/starting/stopping) enterprises per municipality:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92707cf4-2348-4a17-8599-e80d8fd324c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_by_muni = df.groupby(\"CD_REFNIS\")[['MS_NUM_VAT', 'MS_NUM_VAT_START', 'MS_NUM_VAT_STOP']].sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75cabfba-f049-492a-9c6a-42caa606ba86",
   "metadata": {},
   "source": [
    "And add a new column with the relative change in the number of registered enterprises:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92ab1e0e-2a97-4838-9263-85b9720a58c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_by_muni[\"NUM_VAT_CHANGE\"] = (df_by_muni[\"MS_NUM_VAT_START\"] - df_by_muni[\"MS_NUM_VAT_STOP\"]) / df_by_muni[\"MS_NUM_VAT\"] * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f5a1cf6-02a5-4f1c-aa0a-7ba83cac38bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_by_muni"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddff1313-fd9e-4861-89f0-032dafca9a9d",
   "metadata": {},
   "source": [
    "We can now merge the dataframe with the geospatial information of the municipalities with the dataframe with the enterprise numbers:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7427ec23-29f7-46a9-9686-77cafca4f967",
   "metadata": {},
   "outputs": [],
   "source": [
    "joined = pd.merge(stat, df_by_muni, left_on=\"CNIS5_2019\", right_on=\"CD_REFNIS\")\n",
    "joined"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "447e7757-cded-4b00-99bc-529dbb9748cf",
   "metadata": {},
   "source": [
    "With this joined dataframe, we can make a new map, now visualizing the change in number of registered enterprises (\"NUM_VAT_CHANGE\"):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a6fbeae-748c-4f8d-9a68-de62cfbc1423",
   "metadata": {},
   "outputs": [],
   "source": [
    "joined[\"NUM_VAT_CHANGE_CAT\"] = pd.cut(joined[\"NUM_VAT_CHANGE\"], [-15, -6, -4, -2, 2, 4, 6, 15])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50c06378-2b03-4916-8cfc-be2c8daf724c",
   "metadata": {},
   "outputs": [],
   "source": [
    "joined.plot(column=\"NUM_VAT_CHANGE_CAT\", figsize=(10, 10), cmap=\"coolwarm\", legend=True)#k=7, scheme=\"equal_interval\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3b5ad11-9387-46e9-a8f1-64fe61446358",
   "metadata": {},
   "source": [
    "## Combining columns  - ``pd.concat`` with ``axis=1``"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b8e016e-5e29-42a6-bd30-26bdda19ec22",
   "metadata": {},
   "source": [
    "We can use `pd.merge` to combine the columns of two DataFrame based on a common column. If our two DataFrames already have equivalent rows, we can also achieve this basic case using `pd.concat` with specifying `axis=1` (or `axis=\"columns\"`)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e24ffc4-d651-4fbb-bdcf-5a42c6ddb1bd",
   "metadata": {},
   "source": [
    "![](../img/pandas/schema-concat1.svg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa045a3c-119a-4463-affe-b8282c415bd3",
   "metadata": {},
   "source": [
    "Assume we have another DataFrame for the same countries, but with some additional statistics:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13cabbdd-51b3-47d6-b9f8-d0c60fd63fea",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = {'country': ['Belgium', 'France', 'Germany', 'Netherlands', 'United Kingdom'],\n",
    "        'population': [11.3, 64.3, 81.3, 16.9, 64.9],\n",
    "        'area': [30510, 671308, 357050, 41526, 244820],\n",
    "        'capital': ['Brussels', 'Paris', 'Berlin', 'Amsterdam', 'London']}\n",
    "countries = pd.DataFrame(data)\n",
    "countries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f4613a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = {'country': ['Belgium', 'France', 'Netherlands'],\n",
    "        'GDP': [496477, 2650823, 820726],\n",
    "        'area': [8.0, 9.9, 5.7]}\n",
    "country_economics = pd.DataFrame(data).set_index('country')\n",
    "country_economics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3105e789",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.concat([countries, country_economics], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17e2c658-8343-4142-a995-3fb8de9ede08",
   "metadata": {},
   "source": [
    "`pd.concat` matches the different objects based on the index:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "763667a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "countries2 = countries.set_index('country')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c3a72d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "countries2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07814fa5",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.concat([countries2, country_economics], axis=\"columns\")"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "formats": "ipynb,md:myst"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
