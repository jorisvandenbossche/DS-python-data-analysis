{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<p><font size=\"6\"><b> Case study: air quality data of European monitoring stations (AirBase)</b></font></p><br>\n",
    "**AirBase (The European Air quality dataBase): hourly measurements of all air quality monitoring stations from Europe. **\n",
    "\n",
    "> *DS Data manipulation, analysis and visualisation in Python*  \n",
    "> *December, 2017*\n",
    "\n",
    "> *© 2016, Joris Van den Bossche and Stijn Van Hoey  (<mailto:jorisvandenbossche@gmail.com>, <mailto:stijnvanhoey@gmail.com>). Licensed under [CC BY 4.0 Creative Commons](http://creativecommons.org/licenses/by/4.0/)*\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    },
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import plotnine as pn\n",
    "\n",
    "pd.options.display.max_rows = 8"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the previous notebook, we processed some raw data files of the AirBase air quality data. As a reminder, the data contains hourly concentrations of nitrogen dioxide (NO2) for 4 different measurement stations:\n",
    "\n",
    "- FR04037 (PARIS 13eme): urban background site at Square de Choisy\n",
    "- FR04012 (Paris, Place Victor Basch): urban traffic site at Rue d'Alesia\n",
    "- BETR802: urban traffic site in Antwerp, Belgium\n",
    "- BETN029: rural background site in Houtem, Belgium\n",
    "\n",
    "See http://www.eea.europa.eu/themes/air/interactive/no2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Importing and quick exploration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "We processed the individual data files in the previous notebook, and saved it to a csv file `../data/airbase_data_processed.csv`. Let's import the file here (if you didn't finish the previous notebook, a version of the dataset is also available in `../data/airbase_data.csv`):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "alldata = pd.read_csv('../data/airbase_data.csv', index_col=0, parse_dates=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We only use the data from 1999 onwards:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = alldata['1999':].copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some first exploration with the *typical* functions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "data.head() # tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "data.describe(percentiles=[0.1, 0.5, 0.9])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.plot(figsize=(12,6))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-warning\">\n",
    "<b>ATTENTION!</b>: <br><br>\n",
    "\n",
    "When just using `.plot()` without further notice (selection, aggregation,...)\n",
    " <ul>\n",
    "  <li>Risk of running into troubles by overloading your computer processing (certainly with looooong time series)</li>\n",
    "  <li>Not always the most informative/interpretable visualisation</li>\n",
    "</ul>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Plot only a subset**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Why not just using the `head`/`tail` possibilities?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.tail(500).plot(figsize=(12,6))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Summary figures**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use summary statistics..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.plot(kind='box', ylim=[0,250])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Also with seaborn plots function, just start with some subsets as first impression...\n",
    "\n",
    "As we already have seen previously, the plotting library [seaborn](http://seaborn.pydata.org/generated/seaborn.heatmap.html) provides some high-level plotting functions on top of matplotlib (check the [docs](http://seaborn.pydata.org/examples/index.html)!). One of those functions is `pairplot`, which we can use here to quickly visualize the concentrations at the different stations and their relation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.pairplot(data.tail(5000).dropna())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Is this a tidy dataset ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In principle this is not a tidy dataset. The variable that was measured is the NO2 concentration, and is divided in 4 columns. Of course those measurements were made at different stations, so one could interpet it as separate variables. But in any case, such format typically does not work well with `plotnine` which expects a pure tidy format.\n",
    "\n",
    "\n",
    "Reason to not use a tidy dataset here: \n",
    "\n",
    "* bigger memory use\n",
    "* timeseries functionality like resample works better\n",
    "* pandas plotting already does what we want when having different columns for *some* types of plots (eg line plots of the timeseries)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\">\n",
    "\n",
    "<b>EXERCISE</b>:\n",
    "\n",
    " <ul>\n",
    "  <li>Create a tidy version of this dataset `data_tidy`, ensuring the result has new columns 'station' and 'no2'.</li>\n",
    "  <li>Check how many missing values are contained in the 'no2' column.</li>\n",
    "  <li>Drop the rows with missing values in that column.</li>\n",
    "</ul>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "clear_cell": true
   },
   "outputs": [],
   "source": [
    "# %load _solutions/case4_air_quality_analysis13.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "clear_cell": true
   },
   "outputs": [],
   "source": [
    "# %load _solutions/case4_air_quality_analysis14.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "clear_cell": true
   },
   "outputs": [],
   "source": [
    "# %load _solutions/case4_air_quality_analysis15.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the following exercises we will mostly do our analysis on `data`and often use pandas (or seaborn) plotting, but once we produced some kind of summary dataframe as the result of an analysis, then it becomes more interesting to convert that result to a tidy format to be able to use the more advanced plotting functionality of `plotnine`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercises"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-warning\">\n",
    "\n",
    "<b>REMINDER</b>: <br><br>\n",
    "\n",
    "Take a look at the [Timeseries notebook](pandas_04_time_series_data.ipynb) when you require more info about:\n",
    "\n",
    " <ul>\n",
    "  <li>`resample`</li>\n",
    "  <li>string indexing of DateTimeIndex</li>\n",
    "</ul><br>\n",
    "\n",
    "Take a look at the [matplotlib](visualization_01_matplotlib.ipynb) and [plotnine](visualization_02_plotnine.ipynb) notebooks when you require more info about the plot requirements.\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\">\n",
    "\n",
    "<b>EXERCISE</b>:\n",
    "\n",
    " <ul>\n",
    "  <li>Plot the monthly mean and median concentration of the 'FR04037' station for the years 2009 - 2013 in a single figure/ax</li>\n",
    "</ul>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "clear_cell": true
   },
   "outputs": [],
   "source": [
    "# %load _solutions/case4_air_quality_analysis16.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "clear_cell": true
   },
   "outputs": [],
   "source": [
    "# %load _solutions/case4_air_quality_analysis17.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\">\n",
    "\n",
    "<b>EXERCISE</b>\n",
    "\n",
    " <ul>\n",
    "  <li>Make a violin plot for January 2011 until August 2011 (check out the documentation to improve the plotting settings)</li>\n",
    "  <li>Change the y-label to 'NO$_2$ concentration (µg/m³)'</li>\n",
    "</ul><br>\n",
    "\n",
    "NOTE: \n",
    "\n",
    "When having the data not in a long format but when having different columns for which you want to make violin plots, you can use [seaborn](http://seaborn.pydata.org/examples/index.html).\n",
    "When using the tidy data, we can use `plotnine`.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "clear_cell": true
   },
   "outputs": [],
   "source": [
    "# %load _solutions/case4_air_quality_analysis18.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "clear_cell": true
   },
   "outputs": [],
   "source": [
    "# %load _solutions/case4_air_quality_analysis19.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\">\n",
    "\n",
    "<b>EXERCISE</b>\n",
    "\n",
    " <ul>\n",
    "  <li>Make a bar plot with pandas of the mean of each of the stations in the year 2012 (check the documentation of Pandas plot to adapt the rotation of the labels) and make sure all bars have the same color.</li>\n",
    "  <li>Using the matplotlib objects, change the y-label to 'NO$_2$ concentration (µg/m³)</li>\n",
    "  <li>Add a 'darkorange' horizontal line on the ax for the y-value 40 µg/m³ (command for horizontal line from matplotlib: `axhline`).</li>\n",
    "  <li>[Place the text](visualization_01_matplotlib.ipynb) 'Yearly limit is 40 µg/m³' just above the 'darkorange' line.</li>\n",
    "</ul><br>\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "clear_cell": true
   },
   "outputs": [],
   "source": [
    "# %load _solutions/case4_air_quality_analysis20.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\">\n",
    "\n",
    "<b>EXERCISE:</b> Did the air quality improve over time?\n",
    "\n",
    " <ul>\n",
    "  <li>For the data from 1999 till the end, plot the yearly averages</li>\n",
    "  <li>For the same period, add the overall mean (all stations together) as an additional line to the graph, use a thicker black line (`linewidt=4` and `linestyle='--'`)</li>\n",
    "  <li>[OPTIONAL] Add a legend above the ax for all lines</li>\n",
    "  \n",
    "\n",
    "</ul>\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "clear_cell": true
   },
   "outputs": [],
   "source": [
    "# %load _solutions/case4_air_quality_analysis21.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\">\n",
    "\n",
    "<b>REMEMBER</b>: <br><br>\n",
    "\n",
    "`resample` is a specifal version of `groupby`. For example, taking annual means with `data.resample('A').mean()` is equivalent to `data.groupby(data.index.year).mean()` (but the result of `resample` still has a DatetimeIndex).<br><br>\n",
    "\n",
    "Checking the index of the resulting DataFrame when using **groupby** instead of resample: You'll notice that the Index lost the DateTime capabilities:\n",
    "\n",
    "<code>\n",
    "> data.groupby(data.index.year).mean().index\n",
    "</code>\n",
    "\n",
    "Results in:\n",
    "\n",
    "<code>\n",
    "Int64Index([1990, 1991, 1992, 1993, 1994, 1995, 1996, 1997, 1998, 1999, 2000,\n",
    "            2001, 2002, 2003, 2004, 2005, 2006, 2007, 2008, 2009, 2010, 2011,\n",
    "            2012],\n",
    "           dtype='int64')$\n",
    "</code>\n",
    "\n",
    "<br>\n",
    "When using **resample**, we keep the DateTime capabilities:\n",
    "\n",
    "<code>\n",
    "> data.resample('A').mean().index\n",
    "</code>\n",
    "Results in:\n",
    "<code>\n",
    "DatetimeIndex(['1999-12-31', '2000-12-31', '2001-12-31', '2002-12-31',\n",
    "               '2003-12-31', '2004-12-31', '2005-12-31', '2006-12-31',\n",
    "               '2007-12-31', '2008-12-31', '2009-12-31', '2010-12-31',\n",
    "               '2011-12-31', '2012-12-31'],\n",
    "              dtype='datetime64[ns]', freq='A-DEC')\n",
    "</code>\n",
    "<br>\n",
    "But, `groupby` is more flexible and can also do resamples that do not result in a new continuous time series, e.g. by grouping by the hour of the day to get the diurnal cycle.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\">\n",
    "\n",
    "<b>EXERCISE</b>\n",
    "\n",
    " <ul>\n",
    "  <li>How does the *typical yearly profile* (typical averages for the different months) look like for the different stations? (add a 'month' column as a first step)</li>\n",
    "\n",
    "</ul>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "clear_cell": true
   },
   "outputs": [],
   "source": [
    "# %load _solutions/case4_air_quality_analysis22.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.drop(\"month\", axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: Technically, we could reshape the result of the groupby operation to a tidy format (we no longer have a real time series), but since we already have the things we want to plot as lines in different columns, doing `.plot` already does what we want."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\">\n",
    "\n",
    "<b>EXERCISE</b>\n",
    "\n",
    " <ul>\n",
    "  <li>Plot the weekly 95% percentiles of the concentration in 'BETR801' and 'BETN029' for 2011</li>\n",
    "\n",
    "</ul>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "clear_cell": true
   },
   "outputs": [],
   "source": [
    "# %load _solutions/case4_air_quality_analysis24.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "clear_cell": true
   },
   "outputs": [],
   "source": [
    "# %load _solutions/case4_air_quality_analysis25.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\">\n",
    "\n",
    "<b>EXERCISE</b>\n",
    "\n",
    " <ul>\n",
    "  <li>Plot the typical diurnal profile (typical hourly averages) for the different stations taking into account the whole time period.</li>\n",
    "\n",
    "</ul>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "clear_cell": true
   },
   "outputs": [],
   "source": [
    "# %load _solutions/case4_air_quality_analysis26.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\">\n",
    "\n",
    "<b>EXERCISE</b> <br><br>\n",
    "\n",
    "What is the difference in the typical diurnal profile between week and weekend days? (and visualise it)<br><br>\n",
    "\n",
    "Start with only visualizing the different in diurnal profile for the BETR801 station. In a next step, make the same plot for each station.<br><br>\n",
    "\n",
    "**Hints:**\n",
    "\n",
    " <ul>\n",
    "  <li>Add a column 'weekend' defining if a value of the index is in the weekend (i.e. weekdays 5 and 6) or not</li>\n",
    "  <li>Add a column 'hour' with the hour of the day for each row.</li>\n",
    "  <li>You can groupby on multiple items at the same time.</li>\n",
    "\n",
    "</ul>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "clear_cell": true
   },
   "outputs": [],
   "source": [
    "# %load _solutions/case4_air_quality_analysis27.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "clear_cell": true
   },
   "outputs": [],
   "source": [
    "# %load _solutions/case4_air_quality_analysis28.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "clear_cell": true
   },
   "outputs": [],
   "source": [
    "# %load _solutions/case4_air_quality_analysis29.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "clear_cell": true
   },
   "outputs": [],
   "source": [
    "# %load _solutions/case4_air_quality_analysis30.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "clear_cell": true
   },
   "outputs": [],
   "source": [
    "# %load _solutions/case4_air_quality_analysis31.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "clear_cell": true
   },
   "outputs": [],
   "source": [
    "# %load _solutions/case4_air_quality_analysis32.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.drop(['hour', 'weekend'], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\">\n",
    "\n",
    "<b>EXERCISE</b>:<br><br>\n",
    "\n",
    " <ul>\n",
    "  <li>Calculate the correlation between the different stations (check in the documentation, google \"pandas correlation\" or use the magic function `%psearch`)</li>\n",
    "\n",
    "</ul>\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "clear_cell": true
   },
   "outputs": [],
   "source": [
    "# %load _solutions/case4_air_quality_analysis34.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\">\n",
    "\n",
    "<b>EXERCISE</b>:<br><br>\n",
    "\n",
    "Count the number of exceedances of hourly values above the European limit 200 µg/m3 for each year and station after 2005. Make a barplot of the counts. Add an horizontal line indicating the maximum number of exceedances (which is 18) allowed per year?<br><br>\n",
    "\n",
    "**Hints:**\n",
    "\n",
    " <ul>\n",
    "  <li>Create a new DataFrame, called `exceedances`, (with boolean values) indicating if the threshold is exceeded or not</li>\n",
    "  <li>Remember that the sum of True values can be used to count elements</li>\n",
    "  <li>Adding a horizontal line can be done with the matplotlib function `ax.axhline`</li>\n",
    "\n",
    "\n",
    "</ul>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "clear_cell": true
   },
   "outputs": [],
   "source": [
    "# %load _solutions/case4_air_quality_analysis35.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "clear_cell": true
   },
   "outputs": [],
   "source": [
    "# %load _solutions/case4_air_quality_analysis36.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "clear_cell": true
   },
   "outputs": [],
   "source": [
    "# %load _solutions/case4_air_quality_analysis37.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# More advanced exercises..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = alldata['1999':].copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\">\n",
    "\n",
    "<b>EXERCISE</b>: Perform the following actions for the station `'FR04012'` only:\n",
    "\n",
    " <ul>\n",
    "  <li>Remove the rows containing `Nan` or zero values</li>\n",
    "  <li>Sort the values  of the rows according to the air quality values (low to high values)</li>\n",
    "  <li>Rescale the values to the range [0-1] and store result as `FR_scaled` (Hint: check [wikipedia](https://en.wikipedia.org/wiki/Feature_scaling#Rescaling))</li>\n",
    "  <li>Use pandas to plot these values sorted, not taking into account the dates</li>\n",
    "  <li>Add the station name 'FR04012' as y-label</li>\n",
    "  <li>[OPTIONAL] Add a vertical line to the plot where the line (hence, the values of variable FR_scaled) reach the value `0.3`. You will need the documentation of `np.searchsorted` and matplotlib's `axvline`</li>\n",
    "</ul>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "clear_cell": true
   },
   "outputs": [],
   "source": [
    "# %load _solutions/case4_air_quality_analysis39.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "clear_cell": true
   },
   "outputs": [],
   "source": [
    "# %load _solutions/case4_air_quality_analysis40.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "clear_cell": true,
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "# %load _solutions/case4_air_quality_analysis41.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\">\n",
    "\n",
    "<b>EXERCISE</b>:\n",
    "\n",
    " <ul>\n",
    "  <li>Create a Figure with two subplots (axes), for which both ax**i**s are shared</li>\n",
    "  <li>In the left subplot, plot the histogram (30 bins) of station 'BETN029', only for the year 2009</li>\n",
    "  <li>In the right subplot, plot the histogram (30 bins) of station 'BETR801', only for the year 2009</li>\n",
    "  <li>Add the title representing the station name on each of the subplots, you do not want to have a legend</li>\n",
    "</ul>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "clear_cell": true
   },
   "outputs": [],
   "source": [
    "# %load _solutions/case4_air_quality_analysis42.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "clear_cell": true
   },
   "outputs": [],
   "source": [
    "# %load _solutions/case4_air_quality_analysis43.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\">\n",
    "\n",
    "<b>EXERCISE</b>\n",
    "\n",
    " <ul>\n",
    "  <li>Make a selection of the original dataset of the data in January 2009, call the resulting variable `subset`</li>\n",
    "  <li>Add a new column, called 'weekday', to the variable `subset` which defines for each data point the day of the week</li>\n",
    "  <li>From the `subset` DataFrame, select only Monday (= day 0) and Sunday (=day 6) and remove the others (so, keep this as variable `subset`)</li>\n",
    "  <li>Change the values of the weekday column in `subset` according to the following mapping: `{0:\"Monday\", 6:\"Sunday\"}`</li>\n",
    "  <li>With plotnine, make a scatter plot of the measurements at 'BETN029' vs 'FR04037', with the color variation based on the weekday. Add a linear regression to this plot.</li>\n",
    "</ul><br>\n",
    "\n",
    "**Note**: If you run into the **SettingWithCopyWarning** and do not know what to do, recheck [pandas_03_selecting_data](pandas_03_selecting_data.ipynb)\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "clear_cell": true
   },
   "outputs": [],
   "source": [
    "# %load _solutions/case4_air_quality_analysis44.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "clear_cell": true
   },
   "outputs": [],
   "source": [
    "# %load _solutions/case4_air_quality_analysis45.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "clear_cell": true
   },
   "outputs": [],
   "source": [
    "# %load _solutions/case4_air_quality_analysis46.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\">\n",
    "\n",
    "<b>EXERCISE</b>:\n",
    "\n",
    " <ul>\n",
    "  <li>The maximum daily, 8 hour mean, should be below 100 µg/m³. What is the number of exceedances of this limit for each year/station?</li><br><br>\n",
    "  </ul>\n",
    " \n",
    "  \n",
    "**Tip:**<br>\n",
    "\n",
    "Have a look at the `rolling` method to perform moving window operations.<br><br>\n",
    "\n",
    "**Note:**<br>\n",
    "This is not an actual limit for NO$_2$, but a nice exercise to introduce the `rolling` method. Other pollutans, such as 0$_3$ have actually such kind of limit values based on 8-hour means.\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "clear_cell": true,
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "# %load _solutions/case4_air_quality_analysis47.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "clear_cell": true,
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "# %load _solutions/case4_air_quality_analysis48.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "<div class=\"alert alert-success\">\n",
    "\n",
    "<b>EXERCISE</b>:\n",
    "\n",
    " <ul>\n",
    "  <li>Visualize the typical week profile for station 'BETR801' as boxplots (where the values in one boxplot are the *daily means* for the different *weeks* for a certain weekday).</li><br><br>\n",
    "  </ul>\n",
    " \n",
    "  \n",
    "**Tip:**<br>\n",
    "\n",
    "The boxplot method of a DataFrame expects the data for the different boxes in different columns. For this, you can either use `pivot_table` or a combination of `groupby` and `unstack`\n",
    "\n",
    "\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "clear_cell": true
   },
   "outputs": [],
   "source": [
    "# %load _solutions/case4_air_quality_analysis49.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "clear_cell": true,
    "run_control": {
     "frozen": false,
     "read_only": false
    },
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "# %load _solutions/case4_air_quality_analysis50.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "clear_cell": true
   },
   "outputs": [],
   "source": [
    "# %load _solutions/case4_air_quality_analysis51.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "clear_cell": true,
    "run_control": {
     "frozen": false,
     "read_only": false
    },
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "# %load _solutions/case4_air_quality_analysis52.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "clear_cell": true,
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "# %load _solutions/case4_air_quality_analysis53.py"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Nbtutor - export exercises",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  },
  "nav_menu": {},
  "toc": {
   "navigate_menu": true,
   "number_sections": true,
   "sideBar": true,
   "threshold": 6,
   "toc_cell": false,
   "toc_section_display": "block",
   "toc_window_display": true
  },
  "toc_position": {
   "height": "860px",
   "left": "0px",
   "right": "1657px",
   "top": "106px",
   "width": "212px"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
